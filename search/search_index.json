{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"\u7b2c\u4e09\u671f\u4e66\u751f\u00b7\u6d66\u8bed\u5b9e\u6218\u8425\u5b66\u4e60\u7b14\u8bb0\u53ca\u4f5c\u4e1a\u63d0\u4ea4","text":""},{"location":"#_2","title":"\u4e00\u3001\u5165\u95e8\u5c9b","text":""},{"location":"#11-linux","title":"1.1 Linux \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"#12-python","title":"1.2 Python \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"#13-git","title":"1.3 Git \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"#_3","title":"\u4e8c\u3001\u57fa\u7840\u5c9b","text":""},{"location":"#21","title":"2.1 \u4e66\u751f\u5927\u6a21\u578b\u5168\u94fe\u8def\u5f00\u6e90\u4f53\u7cfb","text":""},{"location":"#22-8g-demo","title":"2.2 8G \u663e\u5b58\u73a9\u8f6c\u4e66\u751f\u5927\u6a21\u578b Demo","text":""},{"location":"#23","title":"2.3 \u6d66\u8bed\u63d0\u793a\u8bcd\u5de5\u7a0b\u5b9e\u8df5","text":""},{"location":"#24-internlm-llamaindex-rag","title":"2.4 InternLM + LlamaIndex RAG \u5b9e\u8df5","text":""},{"location":"#25-xtuner","title":"2.5 XTuner \u5fae\u8c03\u4e2a\u4eba\u5c0f\u52a9\u624b\u8ba4\u77e5","text":""},{"location":"#26-opencompass-internlm-18b","title":"2.6 OpenCompass \u8bc4\u6d4b InternLM-1.8B \u5b9e\u8df5","text":""},{"location":"#_4","title":"\u4e09\u3001\u8fdb\u9636\u5c9b","text":""},{"location":"#31-internlm","title":"3.1 \u63a2\u7d22 InternLM \u6a21\u578b\u80fd\u529b\u8fb9\u754c","text":""},{"location":"#32-lagent-agent","title":"3.2 Lagent \u81ea\u5b9a\u4e49\u4f60\u7684 Agent \u667a\u80fd\u4f53","text":""},{"location":"#33-lmdeploy","title":"3.3 LMDeploy \u91cf\u5316\u90e8\u7f72\u8fdb\u9636\u5b9e\u8df5","text":""},{"location":"#34-internvl","title":"3.4 InternVL \u591a\u6a21\u6001\u6a21\u578b\u90e8\u7f72\u5fae\u8c03\u5b9e\u8df5","text":""},{"location":"#35","title":"3.5 \u8334\u9999\u8c46\uff1a\u4f01\u4e1a\u7ea7\u77e5\u8bc6\u5e93\u95ee\u7b54\u5de5\u5177","text":""},{"location":"#_5","title":"\u56db\u3001\u5b9e\u6218\u5c9b","text":""},{"location":"#41-llama3-1","title":"4.1 Llama3-1","text":""},{"location":"#42-minerurag","title":"4.2 MinerU\u63d0\u53d6\u8bba\u6587\u5e76RAG\u5316","text":""},{"location":"#43-agi","title":"4.3 AGI\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\u672c\u5730\u90e8\u7f72","text":""},{"location":"1.%E5%85%A5%E9%97%A8%E5%B2%9B/","title":"\u4e00\u3001\u5165\u95e8\u5c9b","text":""},{"location":"1.%E5%85%A5%E9%97%A8%E5%B2%9B/#11-linux","title":"1.1 Linux \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"1.%E5%85%A5%E9%97%A8%E5%B2%9B/#12-python","title":"1.2 Python \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"1.%E5%85%A5%E9%97%A8%E5%B2%9B/#13-git","title":"1.3 Git \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/","title":"\u4e8c\u3001\u57fa\u7840\u5c9b","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/#21","title":"2.1 \u4e66\u751f\u5927\u6a21\u578b\u5168\u94fe\u8def\u5f00\u6e90\u4f53\u7cfb","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/#22-8g-demo","title":"2.2 8G \u663e\u5b58\u73a9\u8f6c\u4e66\u751f\u5927\u6a21\u578b Demo","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/#23","title":"2.3 \u6d66\u8bed\u63d0\u793a\u8bcd\u5de5\u7a0b\u5b9e\u8df5","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/#24-internlm-llamaindex-rag","title":"2.4 InternLM + LlamaIndex RAG \u5b9e\u8df5","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/#25-xtuner","title":"2.5 XTuner \u5fae\u8c03\u4e2a\u4eba\u5c0f\u52a9\u624b\u8ba4\u77e5","text":""},{"location":"2.%E5%9F%BA%E7%A1%80%E5%B2%9B/#26-opencompass-internlm-18b","title":"2.6 OpenCompass \u8bc4\u6d4b InternLM-1.8B \u5b9e\u8df5","text":""},{"location":"3.%E8%BF%9B%E9%98%B6%E5%B2%9B/","title":"\u4e09\u3001 \u8fdb\u9636\u5c9b","text":""},{"location":"3.%E8%BF%9B%E9%98%B6%E5%B2%9B/#31-internlm","title":"3.1 \u63a2\u7d22 InternLM \u6a21\u578b\u80fd\u529b\u8fb9\u754c","text":""},{"location":"3.%E8%BF%9B%E9%98%B6%E5%B2%9B/#32-lagent-agent","title":"3.2 Lagent \u81ea\u5b9a\u4e49\u4f60\u7684 Agent \u667a\u80fd\u4f53","text":""},{"location":"3.%E8%BF%9B%E9%98%B6%E5%B2%9B/#33-lmdeploy","title":"3.3 LMDeploy \u91cf\u5316\u90e8\u7f72\u8fdb\u9636\u5b9e\u8df5","text":""},{"location":"3.%E8%BF%9B%E9%98%B6%E5%B2%9B/#34-internvl","title":"3.4 InternVL \u591a\u6a21\u6001\u6a21\u578b\u90e8\u7f72\u5fae\u8c03\u5b9e\u8df5","text":""},{"location":"3.%E8%BF%9B%E9%98%B6%E5%B2%9B/#35","title":"3.5 \u8334\u9999\u8c46\uff1a\u4f01\u4e1a\u7ea7\u77e5\u8bc6\u5e93\u95ee\u7b54\u5de5\u5177","text":""},{"location":"4.%E5%AE%9E%E6%88%98%E5%B2%9B/","title":"\u56db\u3001 \u5b9e\u6218\u5c9b","text":""},{"location":"4.%E5%AE%9E%E6%88%98%E5%B2%9B/#41-llama3-1","title":"4.1 Llama3-1","text":""},{"location":"4.%E5%AE%9E%E6%88%98%E5%B2%9B/#42-minerurag","title":"4.2 MinerU\u63d0\u53d6\u8bba\u6587\u5e76RAG\u5316","text":""},{"location":"4.%E5%AE%9E%E6%88%98%E5%B2%9B/#43-agi","title":"4.3 AGI\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\u672c\u5730\u90e8\u7f72","text":""},{"location":"5.%E5%BD%A9%E8%9B%8B%E5%B2%9B/","title":"\u4e94\u3001 \u5f69\u86cb\u5c9b","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/","title":"4.1 Llama3-1","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_1","title":"\u4e00\u3001\u6982\u8981","text":"<p>Llama3.1\u57fa\u7840\u6a21\u578b\u7684\u4e0b\u8f7d\uff0c\u8fdb\u884c\u5fae\u8c03\u3001\u91cf\u5316\u548c\u90e8\u7f72\u53ca\u5e94\u7528\u3002</p> <p>\u5b98\u65b9\u6587\u6863</p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_2","title":"\u4e8c\u3001\u6a21\u578b\u4e0b\u8f7d","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#21","title":"2.1. \u8bb8\u53ef\u534f\u8bae","text":"<p>\u8bb8\u53ef\u534f\u8bae</p> <p>\u6a21\u578b\u7533\u8bf7\u5730\u5740</p> <ul> <li> <p>\u4fe1\u606f\u586b\u5199 </p> <p></p> </li> <li> <p>\u8bb8\u53ef\u52fe\u9009</p> <p></p> </li> <li> <p>\u83b7\u53d6\u5230\u9a8c\u8bc1URL\u5730\u5740(24\u5c0f\u65f6\u6709\u6548)</p> <p></p> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#22","title":"2.2. \u6e90\u7801\u4e0b\u8f7d","text":"<ul> <li> <p>Step1 \u83b7\u53d6\u6e90\u7801 </p> <p>github\u5730\u5740</p> <p><code>git clone https://github.com/meta-llama/llama-models.git</code></p> </li> <li> <p>Step2 \u8fd0\u884cdownload.sh\u811a\u672c</p> <p><code>bash ./download.sh</code></p> <ul> <li> <p>\u6ce8\u610f\u4f7f\u7528bash \u6267\u884c download.sh </p> <p>issue</p> </li> </ul> </li> <li> <p>Step3 \u6a21\u578b\u4e0b\u8f7d-\u8f93\u5165\u9a8c\u8bc1URL\u5730\u5740</p> <p></p> <p></p> </li> <li> <p>Step4 \u6a21\u578b\u4e0b\u8f7d-\u9009\u62e9\u6a21\u578b</p> <ul> <li>meta-llama-3.1-405b</li> <li>meta-llama-3.1-70b</li> <li>meta-llama-3.1-8b</li> <li>meta-llama-guard-3-8b</li> <li>prompt-guard</li> </ul> <p></p> <ul> <li>\u9700\u8981\u79d1\u5b66\u4e0a\u7f51</li> </ul> <p></p> </li> <li> <p>Step5 \u6a21\u578b\u4e0b\u8f7d-\u6a21\u578b\u6587\u4ef6\u5939\u7ed3\u6784</p> <pre><code>    \u2500\u2500 api\n    \u2502?? \u251c\u2500\u2500 args.py\n    \u2502?? \u251c\u2500\u2500 chat_format.py\n    \u2502?? \u251c\u2500\u2500 datatypes.py\n    \u2502?? \u251c\u2500\u2500 __init__.py\n    \u2502?? \u251c\u2500\u2500 interface.py\n    \u2502?? \u251c\u2500\u2500 model.py\n    \u2502?? \u251c\u2500\u2500 sku_list.py\n    \u2502?? \u251c\u2500\u2500 templates\n    \u2502?? \u2502?? \u251c\u2500\u2500 assistant_message.builtin_tool_call.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 assistant_message.custom_tool_call.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 assistant_message.default.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 assistant_message.jinja\n    \u2502?? \u2502?? \u251c\u2500\u2500 system_message.builtin_and_custom_tools.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 system_message.builtin_tools_only.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 system_message.custom_tools_only.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 system_message.default.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 system_message.jinja\n    \u2502?? \u2502?? \u251c\u2500\u2500 tool_message.failure.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 tool_message.jinja\n    \u2502?? \u2502?? \u251c\u2500\u2500 tool_message.success.yaml\n    \u2502?? \u2502?? \u251c\u2500\u2500 user_message.default.yaml\n    \u2502?? \u2502?? \u2514\u2500\u2500 user_message.jinja\n    \u2502?? \u251c\u2500\u2500 test_tokenizer.py\n    \u2502?? \u251c\u2500\u2500 tokenizer.model\n    \u2502?? \u251c\u2500\u2500 tokenizer.py\n    \u2502?? \u2514\u2500\u2500 tool_utils.py\n    \u251c\u2500\u2500 download.sh\n    \u251c\u2500\u2500 eval_details.md\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 Meta-Llama-3.1-405B-Instruct-MP16\n    \u2502?? \u251c\u2500\u2500 consolidated.00.pth\n    \u2502?? \u251c\u2500\u2500 consolidated.01.pth\n    \u2502?? \u251c\u2500\u2500 consolidated.02.pth\n    \u2502?? \u251c\u2500\u2500 consolidated.03.pth\n    \u2502?? \u2514\u2500\u2500 tokenizer.model\n    \u251c\u2500\u2500 MODEL_CARD.md\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 requirements.txt\n    \u2514\u2500\u2500 USE_POLICY.md\n</code></pre> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#23-hf","title":"2.3. HF\u4e0b\u8f7d","text":"<p>HF \u5408\u96c6\u5730\u5740</p> <p></p> <ul> <li>Step1 \u8bb8\u53ef\u4fe1\u606f\u586b\u5199</li> </ul> <p></p> <ul> <li>\u7b49\u5f85\u8bb8\u53ef\u901a\u8fc7</li> </ul> <p></p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#24-ollama","title":"2.4 ollama \u4e0b\u8f7d","text":"<p>ollma llama3.1 \u5730\u5740</p> <p></p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_3","title":"\u4e09\u3001\u5feb\u901f\u4f53\u9a8c","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#31","title":"3.1 \u5e94\u7528\u5feb\u901f\u4f53\u9a8c","text":"<p>Try 405B on Meta AI</p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#32","title":"3.2 \u6a21\u578b\u5feb\u901f\u4f53\u9a8c","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#321-ollama-llama31","title":"3.2.1 ollama \u672c\u5730\u8fd0\u884c\u91cf\u5316llama3.1\u6a21\u578b","text":"<ul> <li> <p>\u9009\u53d6\u91cf\u5316\u6a21\u578b</p> <p></p> </li> <li> <p>\u590d\u5236\u5bf9\u5e94\u91cf\u5316\u6a21\u578b\u7684\u547d\u4ee4</p> <p><code>ollama run llama3.1:8b-instruct-q4_K_S</code></p> <p></p> <p></p> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_4","title":"\u56db\u3001\u5fae\u8c03","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_5","title":"\u4e94\u3001\u91cf\u5316","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_6","title":"\u516d\u3001\u90e8\u7f72\u53ca\u5e94\u7528","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_7","title":"\u9b54\u642d","text":"<ul> <li>llama3.1 405B\u4f53\u9a8c\u9875\u9762</li> </ul> <ul> <li> <p>\u6e90\u7801\uff1a</p> <p><code>git clone https://www.modelscope.cn/studios/LLM-Research/Meta-Llama-3.1-405B-Instruct-FP8-demo.git</code></p> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#_8","title":"\u4e03\u3001\u8bba\u6587\u89e3\u8bfb","text":"<p>\u94fe\u63a5\u5730\u5740  the-llama-3-herd-of-models</p> <p>\u6e90\u6587\u4ef6  The Llama 3 Herd of Models.pdf</p> <p>\u535a\u5ba2  Introducing Llama 3.1: Our most capable models to date</p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#71","title":"7.1 \u8bba\u6587\u6458\u8981","text":"<pre><code>&gt; Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.\n\n&gt;\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd (AI) \u7cfb\u7edf\u7531\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u7ec4\u65b0\u7684\u57fa\u7840\u6a21\u578b\uff0c\u79f0\u4e3a Llama 3\u3002\u8fd9\u662f\u4e00\u7fa4\u539f\u751f\u652f\u6301\u591a\u8bed\u8a00\u3001\u7f16\u7801\u3001\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u7684\u8bed\u8a00\u6a21\u578b\u3002\u6211\u4eec\u6700\u5927\u7684\u6a21\u578b\u662f\u4e00\u4e2a\u5177\u6709 4050 \u4ebf\u4e2a\u53c2\u6570\u548c\u6700\u591a 128K \u4e2a\u6807\u8bb0\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u5bc6\u96c6 Transformer\u3002\u672c\u6587\u5bf9 Llama 3 \u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002\u6211\u4eec\u53d1\u73b0 Llama 3 \u5728\u5927\u91cf\u4efb\u52a1\u4e0a\u63d0\u4f9b\u4e0e GPT-4 \u7b49\u9886\u5148\u8bed\u8a00\u6a21\u578b\u76f8\u5f53\u7684\u8d28\u91cf\u3002\u6211\u4eec\u516c\u5f00\u53d1\u5e03\u4e86 Llama 3\uff0c\u5305\u62ec 4050 \u4ebf\u53c2\u6570\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u7248\u672c\uff0c\u4ee5\u53ca\u6211\u4eec\u7684 Llama Guard 3 \u6a21\u578b\uff0c\u7528\u4e8e\u8f93\u5165\u548c\u8f93\u51fa\u5b89\u5168\u3002\u672c\u6587\u8fd8\u4ecb\u7ecd\u4e86\u5c06\u56fe\u50cf\u3001\u89c6\u9891\u548c\u8bed\u97f3\u529f\u80fd\u901a\u8fc7\u7ec4\u5408\u65b9\u6cd5\u96c6\u6210\u5230 Llama 3 \u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002\u6211\u4eec\u89c2\u5bdf\u5230\u8fd9\u79cd\u65b9\u6cd5\u5728\u56fe\u50cf\u3001\u89c6\u9891\u548c\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u6280\u672f\u7ade\u4e89\u3002\u7531\u4e8e\u8fd9\u4e9b\u6a21\u578b\u4ecd\u5728\u5f00\u53d1\u4e2d\uff0c\u56e0\u6b64\u5c1a\u672a\u5e7f\u6cdb\u53d1\u5e03\u3002\n\n&gt; AI\u603b\u7ed3\uff1aMeta AI \u8fd1\u65e5\u53d1\u5e03\u4e86\u4e00\u7cfb\u5217\u540d\u4e3a Llama 3 \u7684\u57fa\u7840\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u662f\u8bed\u8a00\u6a21\u578b\u7684\u96c6\u5408\uff0c\u80fd\u591f\u539f\u751f\u652f\u6301\u591a\u8bed\u8a00\u3001\u7f16\u7801\u3001\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u3002Llama 3 \u4e2d\u6700\u5927\u7684\u6a21\u578b\u662f\u4e00\u4e2a\u62e5\u6709 4050 \u4ebf\u53c2\u6570\u7684\u5bc6\u96c6 Transformer\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3\u9ad8\u8fbe 128K \u4e2a token\u3002\n\u8bba\u6587\u5bf9 Llama 3 \u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b83\u5728\u4f17\u591a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e GPT-4 \u7b49\u9886\u5148\u7684\u8bed\u8a00\u6a21\u578b\u76f8\u5f53\u3002Meta \u516c\u5f00\u53d1\u5e03\u4e86 Llama 3\uff0c\u5305\u62ec 4050 \u4ebf\u53c2\u6570\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u7248\u672c\uff0c\u4ee5\u53ca\u7528\u4e8e\u8f93\u5165\u548c\u8f93\u51fa\u5b89\u5168\u7684 Llama Guard 3 \u6a21\u578b\u3002\n\u8bba\u6587\u8fd8\u5c55\u793a\u4e86\u901a\u8fc7\u7ec4\u5408\u65b9\u6cd5\u5c06\u56fe\u50cf\u3001\u89c6\u9891\u548c\u8bed\u97f3\u529f\u80fd\u6574\u5408\u5230 Llama 3 \u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u56fe\u50cf\u3001\u89c6\u9891\u548c\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e\u6700\u5148\u8fdb\u6280\u672f\u76f8\u5f53\u3002\u4f46\u7531\u4e8e\u8fd9\u4e9b\u6a21\u578b\u4ecd\u5728\u5f00\u53d1\u4e2d\uff0c\u5c1a\u672a\u5e7f\u6cdb\u53d1\u5e03\u3002\nLlama 3 \u7684\u53d1\u5e03\u662f Meta \u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u4e00\u9879\u91cd\u5927\u8fdb\u5c55\uff0c\u6807\u5fd7\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u3001\u7f16\u7801\u3001\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u7b49\u65b9\u9762\u7684\u80fd\u529b\u6b63\u5728\u4e0d\u65ad\u63d0\u5347\u3002\u672a\u6765\uff0cMeta \u5c06\u7ee7\u7eed\u63a2\u7d22\u548c\u5f00\u53d1\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5e94\u7528\uff0c\u4e3a\u4eba\u7c7b\u793e\u4f1a\u521b\u9020\u66f4\u591a\u4ef7\u503c\u3002\n</code></pre>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.1%20Llama3-1/#72-llama3","title":"7.2 llama3\u4ecb\u7ecd\u603b\u7ed3","text":"<pre><code>AI\u603b\u7ed3\uff1a\n&gt;  Meta\u53d1\u5e03\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5f3a\u5927\u7684\u5f00\u6e90\u6a21\u578bLlama 3.1\uff0c\u5176405B\u7248\u672c\u5728\u80fd\u529b\u4e0a\u5ab2\u7f8e\u6700\u5148\u8fdb\u7684\u95ed\u6e90\u6a21\u578b\uff0c\u6807\u5fd7\u7740\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u5165\u4e86\u4e00\u4e2a\u65b0\u65f6\u4ee3\u3002\n\n&gt;Llama 3.1 405B \u5728\u901a\u7528\u77e5\u8bc6\u3001\u53ef\u63a7\u6027\u3001\u6570\u5b66\u3001\u5de5\u5177\u4f7f\u7528\u548c\u591a\u8bed\u8a00\u7ffb\u8bd1\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\u3002\u5b83\u53ef\u4ee5\u7528\u4e8e\u5404\u79cd\u5e94\u7528\u573a\u666f\uff0c\u4f8b\u5982\u5408\u6210\u6570\u636e\u751f\u6210\uff0c\u6a21\u578b\u84b8\u998f\uff0c\u957f\u7bc7\u6587\u672c\u6458\u8981\uff0c\u591a\u8bed\u8a00\u5bf9\u8bdd\u4ee3\u7406\u548c\u7f16\u7801\u52a9\u624b\u3002\n\n&gt;Llama 3.1 405B \u662f\u7b2c\u4e00\u4e2a\u5728\u89c4\u6a21\u548c\u80fd\u529b\u4e0a\u4e0e GPT-4 \u7b49\u95ed\u6e90\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u5f00\u6e90\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5728\u8d85\u8fc7 15 \u4e07\u4ebf\u4e2a\u6807\u8bb0\u4e0a\u8bad\u7ec3\uff0c\u4f7f\u7528\u4e86\u8d85\u8fc7 16000 \u4e2a H100 GPU\u3002\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u7a33\u5b9a\u6027\uff0cMeta \u91c7\u7528\u4e86\u6807\u51c6\u7684\u89e3\u7801\u5668-\u53ea transformer \u6a21\u578b\u67b6\u6784\uff0c\u5e76\u8fdb\u884c\u4e86\u8fed\u4ee3\u5f0f\u540e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5305\u62ec\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3002\n\n&gt;Meta \u8fd8\u53d1\u5e03\u4e86 Llama 3.1 8B \u548c 70B \u7248\u672c\uff0c\u5b83\u4eec\u652f\u6301\u591a\u8bed\u8a00\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55\u5230 128K\uff0c\u5e76\u5177\u6709\u66f4\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002\u6b64\u5916\uff0cMeta \u8fd8\u63a8\u51fa\u4e86 Llama Guard 3 \u548c Prompt Guard \u7b49\u5b89\u5168\u5de5\u5177\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u7684\u8d1f\u8d23\u4efb\u4f7f\u7528\u3002\n\n&gt;Meta \u81f4\u529b\u4e8e\u6253\u9020\u4e00\u4e2a\u5b8c\u6574\u7684 Llama \u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5305\u62ec\u591a\u4e2a\u7ec4\u4ef6\uff0c\u4f8b\u5982\u5916\u90e8\u5de5\u5177\u8c03\u7528\uff0c\u5b89\u5168\u6a21\u578b\u548c\u63d0\u793a\u6ce8\u5165\u8fc7\u6ee4\u5668\u3002Meta \u8fd8\u53d1\u5e03\u4e86 Llama Stack API \u7684\u8bf7\u6c42\u610f\u89c1\uff0c\u5e0c\u671b\u80fd\u591f\u4e3a\u7b2c\u4e09\u65b9\u9879\u76ee\u63d0\u4f9b\u4e00\u4e2a\u6807\u51c6\u63a5\u53e3\uff0c\u4ee5\u4fbf\u66f4\u5bb9\u6613\u5730\u5229\u7528 Llama \u6a21\u578b\u3002\nM\n&gt;eta \u76f8\u4fe1 Llama 3.1 \u7684\u53d1\u5e03\u5c06\u63a8\u52a8\u5f00\u6e90\u793e\u533a\u7684\u521b\u65b0\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u66f4\u591a\u5de5\u5177\u6765\u6784\u5efa\u65b0\u7684\u5e94\u7528\u3002Meta \u671f\u5f85\u770b\u5230\u793e\u533a\u5229\u7528 Llama 3.1 \u6784\u5efa\u66f4\u591a\u6709\u7528\u7684\u4ea7\u54c1\u548c\u4f53\u9a8c\u3002\n</code></pre>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/","title":"4.2 MinerU\u63d0\u53d6\u8bba\u6587\u5e76RAG\u5316","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#magic-pdf","title":"magic-pdf","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#_1","title":"\u53c2\u8003","text":"<ul> <li> <p>MinerU\u5b89\u88c5\u6587\u6863</p> </li> <li> <p>MinerU github\u5730\u5740</p> </li> <li> <p>\u6ce2\u52a8\u667a\u80fdgithub\u5730\u5740</p> </li> <li> <p>\u7ec8\u8eab\u4e2a\u6027\u5316AI  LPA</p> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#_2","title":"\u4f9d\u8d56\u5e93\u5b89\u88c5","text":"<p><code>pip install detectron2 --extra-index-url https://myhloli.github.io/wheels/ -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p> <p><code>pip install magic-pdf[full]==0.6.2b1 -i https://mirrors.aliyun.com/pypi/simple/</code></p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#_3","title":"\u6a21\u578b\u4e0b\u8f7d","text":"<ul> <li>\u53c2\u8003</li> </ul> <pre><code>import os\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n\n# \u4e0b\u8f7d\u6a21\u578b\nos.system('huggingface-cli download --resume-download wanderkid/PDF-Extract-Kit --local-dir /root/pro/model/PDF-Extract-Kit')\n</code></pre>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#_4","title":"\u6e90\u7801\u4e0b\u8f7d","text":"<p><code>cp magic-pdf.template.json ~/magic-pdf.json</code></p> <ul> <li> <p>\u914d\u7f6e\u6587\u4ef6</p> <p><code>https://github.com/opendatalab/MinerU.git</code></p> <pre><code>{\n\"bucket_info\":{\n    \"bucket-name-1\":[\"ak\", \"sk\", \"endpoint\"],\n    \"bucket-name-2\":[\"ak\", \"sk\", \"endpoint\"]\n},\n\"temp-output-dir\":\"/tmp\",\n\"models-dir\":\"root/pro/model/PDF-Extract-Kit/models\",\n\"device-mode\":\"cuda\"\n}\n</code></pre> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#gpu","title":"GPU\u652f\u6301","text":"<p><code>pip install --force-reinstall torch==2.3.1 torchvision==0.18.1 --index-url https://download.pytorch.org/whl/cu118</code></p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#_5","title":"\u8fd0\u884c","text":"<p><code>magic-pdf pdf-command --pdf \"/root/pro/files\" --inside_model true</code></p> <p><code>magic-pdf pdf-command --pdf \"/root/pro/files/SUAN0.3.pdf\" --inside_model true</code></p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#magic-doc","title":"magic-doc","text":"<p>https://github.com/opendatalab/magic-doc</p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.2%20MinerU%E6%8F%90%E5%8F%96%E8%AE%BA%E6%96%87%E5%B9%B6RAG%E5%8C%96/#magic-html","title":"magic-html","text":"<p>https://github.com/opendatalab/magic-html</p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/","title":"4.3 AGI\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\u672c\u5730\u90e8\u7f72","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_1","title":"\u4e00\u3001\u529f\u80fd","text":"<p>\u5229\u7528\u5f00\u6e90\u9879\u76ee\u5feb\u901f\u672c\u5730\u90e8\u7f72AGI\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\u3002</p> <ul> <li>\u96f6\u95e8\u69db<ul> <li>\u65e0\u786c\u4ef6\u8d44\u6e90\u8981\u6c42</li> <li>\u65e0\u6280\u672f\u80cc\u666f\u8981\u6c42</li> <li>\u65e0\u4ee3\u7801\u7f16\u5199\u8981\u6c42</li> </ul> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_2","title":"\u4e8c\u3001\u67b6\u6784","text":"<pre><code>\u524d\u7aefweb\u5e94\u7528\u5c42\u2014\u2014WebUI NextWeb\n</code></pre> <pre><code>\u670d\u52a1\u540e\u7aef\u7ba1\u7406\u5c42\u2014\u2014New API(one API)\n</code></pre> <pre><code>\u672c\u5730\u90e8\u7f72\u5927\u6a21\u578b\u5c42\u2014\u2014LLM Ollama\n</code></pre> <pre><code>\u672c\u5730\u90e8\u7f72\u57fa\u7840\u73af\u5883\u5c42\u2014\u2014Windoes wsl2 docker\n</code></pre>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_3","title":"\u4e09\u3001\u73af\u5883\u642d\u5efa","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#31-windowswsl2","title":"3.1 Windows\u5b89\u88c5wsl2","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#32-windowsdocker-desktop","title":"3.2 Windows\u5b89\u88c5docker desktop","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_4","title":"\u56db\u3001\u90e8\u7f72\u6b65\u9aa4","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#41-ollama-docker","title":"4.1 Ollama docker\u90e8\u7f72","text":"<ul> <li>win \u7ec8\u7aef\u8f93\u5165\u547d\u4ee4 </li> </ul> <p><code>docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama</code></p> <ul> <li>docker wsl IP\u8bbf\u95ee\u5730\u5740</li> </ul> <p><code>ipconfig</code></p> <p></p> <p>http://172.29.80.1:11434/</p> <p></p> <ul> <li>ollama\u5bb9\u5668\u5185\u83b7\u53d6llama3\u5927\u6a21\u578b</li> </ul> <p><code>ollma run llama3</code></p> <p></p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#42-new-api","title":"4.2 New API\u90e8\u7f72","text":"<ul> <li>win \u7ec8\u7aef\u8f93\u5165\u547d\u4ee4</li> </ul> <p><code>docker run --name new-api -d --restart always -p 3000:3000 -e TZ=Asia/Shanghai -v /home/ubuntu/data/new-api:/data calciumion/new-api:latest</code></p> <ul> <li>\u672c\u5730\u8bbf\u95ee\u5730\u5740</li> </ul> <p>http://172.29.80.1:3000/</p>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#43-new-api","title":"4.3 New API\u914d\u7f6e","text":"<ul> <li>\u9ed8\u8ba4\u7528\u6237\u540d\u5bc6\u7801\u767b\u5f55</li> </ul> <p><code>root 123456</code></p> <p></p> <ul> <li> <p>ollama\u6e20\u9053\u914d\u7f6e\uff08\u79d8\u94a5\u4e3a\u5fc5\u586b\u5185\u5bb9\uff0c\u56e0\u4e3a\u672c\u5730\u90e8\u7f72\u5927\u6a21\u578b\uff0c\u56fa\u53ef\u968f\u610f\u586b\u5199\uff09</p> <ol> <li>\u9009\u62e9\u7c7b\u578b\u4e3aollama</li> <li>\u8f93\u5165\u6e20\u9053\u540d\u79f0\u4e3aollama\uff08\u53ef\u4ee5\u4e3a\u5176\u4ed6\uff09</li> <li>\u6e05\u9664\u6240\u6709\u6a21\u578b\u540e\uff0c\u8f93\u5165\u81ea\u5b9a\u4e49\u6a21\u578bllama3\u5e76\u70b9\u51fb\u586b\u5165</li> <li>\u8f93\u5165\u4ee3\u7406\u5730\u5740\u4e3a <code>http://172.29.80.1:11434/</code></li> <li>\u70b9\u51fb\u63d0\u4ea4 </li> <li>\u70b9\u51fb\u6d4b\u8bd5 </li> </ol> </li> <li> <p>\u914d\u7f6e\u4ee4\u724c</p> <ol> <li>\u8f93\u5165\u4ee4\u724c\u540d</li> <li>\u8bbe\u7f6e\u5bf9\u5e94\u6a21\u578b\u4e3allama3 </li> </ol> <p>\u540e\u7eed\u914d\u7f6e\u5b8cNext Web\u9879\u76ee\u540e\u53ef\u8fdb\u884c\u5bf9\u8bdd\u9a8c\u8bc1\u3002</p> </li> <li> <p>\u4f4e\u4ee3\u7801\u754c\u9762\u8bbe\u7f6e</p> <ol> <li>\u516c\u544a</li> <li>\u7cfb\u7edf\u540d</li> <li>logo\u56fe\u7247</li> <li>\u9996\u9875\u5185\u5bb9</li> <li>\u5173\u4e8e</li> <li>\u9875\u811a  </li> </ol> </li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_5","title":"\u4e94\u3001\u6269\u5c55\u5e94\u7528","text":"<ul> <li>\u90e8\u7f72\u5176\u4ed6\u5927\u6a21\u578b</li> <li>\u90e8\u7f72\u5176\u4ed6webui</li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#51-ragflow","title":"5.1 \u90e8\u7f72RAGFlow","text":"<pre><code>git clone https://github.com/infiniflow/ragflow.git\ncd ragflow/docker\ndocker compose -f docker-compose-CN.yml up -d\ndocker logs -f ragflow-server\n</code></pre> <ul> <li>\u672c\u5730\u8bbf\u95eeRAGFlow <code>http://localhost:80</code></li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#52-graphrag","title":"5.2 \u90e8\u7f72GraphRAG","text":""},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_6","title":"\u516d\u3001\u5176\u4ed6\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848","text":"<ul> <li>quivr (\u77e5\u8bc6\u5e93)</li> <li>chat Nio \uff08\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\uff09</li> <li>FastGPT @labring \uff08\u77e5\u8bc6\u5e93\uff09</li> <li>Quivr @quivrhq \uff08\u77e5\u8bc6\u5e93\uff09</li> <li>Bingo @weaigc \uff08\u6a21\u578b\u5e93\uff09</li> <li>Midjourney Proxy @novicezk \uff08\u6a21\u578b\u5e93\uff09</li> <li>phidata ollama \uff08\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\uff09</li> <li>Dify ollama \uff08\u4e00\u7ad9\u5f0f\u89e3\u51b3\u65b9\u6848\uff09</li> </ul>"},{"location":"4.%20%E5%AE%9E%E6%88%98%E5%B2%9B/4.3%20AGI%E4%B8%80%E7%AB%99%E5%BC%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/#_7","title":"\u4e03\u3001 \u53c2\u8003","text":"<p>https://mp.weixin.qq.com/s/F8M6WjuisJJ-wWgWtpwtAg</p> <p>https://mp.weixin.qq.com/s/Qu7Poyu7hhsKgMHWCLL5RQ</p>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"1.1 Linux \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<p>\u95ef\u5173\u4efb\u52a1\u9700\u8981\u5728\u5173\u952e\u6b65\u9aa4\u4e2d\u622a\u56fe\uff1a</p> \u4efb\u52a1\u63cf\u8ff0 \u5b8c\u6210\u6240\u9700\u65f6\u95f4 \u95ef\u5173\u4efb\u52a1 \u5b8c\u6210SSH\u8fde\u63a5\u4e0e\u7aef\u53e3\u6620\u5c04\u5e76\u8fd0\u884c<code>hello_world.py</code> 10min \u53ef\u9009\u4efb\u52a1 1 \u5c06Linux\u57fa\u7840\u547d\u4ee4\u5728\u5f00\u53d1\u673a\u4e0a\u5b8c\u6210\u4e00\u904d 10min \u53ef\u9009\u4efb\u52a1 2 \u4f7f\u7528 VSCODE \u8fdc\u7a0b\u8fde\u63a5\u5f00\u53d1\u673a\u5e76\u521b\u5efa\u4e00\u4e2aconda\u73af\u5883 10min \u53ef\u9009\u4efb\u52a1 3 \u521b\u5efa\u5e76\u8fd0\u884c<code>test.sh</code>\u6587\u4ef6 10min <ul> <li>\u6587\u6863\u5730\u5740</li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_2","title":"\u4e8c\u3001\u95ef\u5173\u4efb\u52a1","text":"<ul> <li>\u4efb\u52a1\u8bf4\u660e\uff1a<code>bash \u5b8c\u6210SSH\u8fde\u63a5\u4e0e\u7aef\u53e3\u6620\u5c04\u5e76\u8fd0\u884chello_world.py</code></li> <li>\u7ed3\u679c\u622a\u56fe<ul> <li>SSH\u8fde\u63a5\u4e0e\u7aef\u53e3\u6620\u5c04 </li> <li>\u8fd0\u884chello_world.py </li> </ul> </li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#1-ssh","title":"\u2460 SSH\u8fde\u63a5\u4e0e\u7aef\u53e3\u6620\u5c04","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_3","title":"\u6b65\u9aa4","text":"<ul> <li> <p>\u8fdb\u5165InternStudio\u5e73\u53f0</p> <ul> <li>InternStudio\u5730\u5740 </li> </ul> </li> <li> <p>\u521b\u5efa\u5f00\u53d1\u673a</p> <ul> <li>1.\u70b9\u9009\u5de6\u4fa7\u83dc\u5355\u680f\u201c\u5f00\u53d1\u673a\u201d</li> <li>2.\u547d\u540d\u5f00\u53d1\u673a</li> <li>3.\u70b9\u51fb\u9009\u62e9\u955c\u50cf</li> <li>4.\u9009\u62e9\u955c\u50cf\u5e76\u4f7f\u7528</li> <li>5.\u9009\u62e9\u8d44\u6e90\u914d\u7f6e </li> </ul> </li> <li> <p>SSH\u8fde\u63a5</p> <ul> <li>\u521b\u5efassh\u79d8\u94a5<ul> <li>1.\u547d\u4ee4\u884c\u8f93\u5165 <code>bash ssh-keygen -t rsa</code></li> <li>2.\u7cfb\u7edf\u7528\u6237.ssh\u6587\u4ef6\u4e0b\u627e\u5230id_rsa.pub</li> <li>3.\u6253\u5f00id_rsa.pub\u83b7\u53d6\u79d8\u94a5 </li> </ul> </li> <li>\u5e73\u53f0\u6dfb\u52a0ssh\u79d8\u94a5<ul> <li>\u53f3\u4e0a\u89d2\u5934\u50cf\u4e0b\u62c9\u70b9\u9009\u201c\u8bbf\u95ee\u7ba1\u7406\u201d</li> <li>\u70b9\u51fb\u201c\u6dfb\u52a0SSH\u516c\u94a5\u201d </li> <li>\u7c98\u8d34\u516c\u94a5</li> <li>\u547d\u540d\u540e\u70b9\u51fb\u6dfb\u52a0 </li> </ul> </li> <li>\u514d\u5bc6\u767b\u5f55<ul> <li>\u70b9\u51fb\u521b\u5efa\u7684\u5f00\u53d1\u673a\u201cSSH\u8fde\u63a5\u201d</li> <li>\u70b9\u51fb\u767b\u5f55\u547d\u4ee4\u201c\u590d\u5236\u201d</li> <li>\u6253\u5f00\u547d\u4ee4\u7ec8\u7aef\u7c98\u8d34\u767b\u5f55\u547d\u4ee4 </li> </ul> </li> <li>\u767b\u5f55\u6210\u529f </li> </ul> </li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#2-hello_worldpy","title":"\u2461 \u8fd0\u884chello_world.py","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_4","title":"\u6b65\u9aa4","text":"<ul> <li> <p>\u8fdb\u5165\u5f00\u53d1\u673avscode</p> <ul> <li>\u70b9\u51fb\u521b\u5efa\u7684\u5f00\u53d1\u673a\"\u8fdb\u5165\u5f00\u53d1\u673a\u201c</li> <li>\u5207\u6362\u9876\u90e8tab\u8fdb\u5165vscode </li> </ul> </li> <li> <p>\u521b\u5efahello_world.py\u6587\u4ef6</p> <ul> <li>ROOT\u6587\u4ef6\u5939\u4e0b\u521b\u5efapro\u6587\u4ef6\u5939</li> <li>pro\u6587\u4ef6\u5939\u4e0b\u521b\u5efahello_world.py\u6587\u4ef6 </li> </ul> </li> <li> <p>\u7f16\u5199hello_world.py\u6587\u4ef6 <pre><code>import socket\nimport re\nimport gradio as gr\n\n# \u83b7\u53d6\u4e3b\u673a\u540d\ndef get_hostname():\n    hostname = socket.gethostname()\n    match = re.search(r'-(\\d+)$', hostname)\n    name = match.group(1)\n\n    return name\n\n# \u521b\u5efa Gradio \u754c\u9762\nwith gr.Blocks(gr.themes.Soft()) as demo:\n    html_code = f\"\"\"\n            &lt;p align=\"center\"&gt;\n            &lt;a href=\"https://intern-ai.org.cn/home\"&gt;\n                &lt;img src=\"https://intern-ai.org.cn/assets/headerLogo-4ea34f23.svg\" alt=\"Logo\" width=\"20%\" style=\"border-radius: 5px;\"&gt;\n            &lt;/a&gt;\n            &lt;/p&gt;\n            &lt;h1 style=\"text-align: center;\"&gt;\u2601\ufe0f Welcome {get_hostname()} user, welcome to the ShuSheng LLM Practical Camp Course!&lt;/h1&gt;\n            &lt;h2 style=\"text-align: center;\"&gt;\ud83d\ude00 Let\u2019s go on a journey through ShuSheng Island together.&lt;/h2&gt;\n            &lt;p align=\"center\"&gt;\n                &lt;a href=\"https://github.com/InternLM/Tutorial/blob/camp3\"&gt;\n                    &lt;img src=\"https://oss.lingkongstudy.com.cn/blog/202406301604074.jpg\" alt=\"Logo\" width=\"20%\" style=\"border-radius: 5px;\"&gt;\n                &lt;/a&gt;\n            &lt;/p&gt;\n\n            \"\"\"\n    gr.Markdown(html_code)\n\ndemo.launch()\n</code></pre></p> </li> <li> <p>\u5b89\u88c5gradio\u4f9d\u8d56\u5305 <code>bash pip install gradio==4.29.0</code> </p> </li> <li> <p>\u8fd0\u884chello_world.py\u6587\u4ef6 <code>python hello_world.py</code> </p> </li> <li> <p>\u672c\u5730\u6d4f\u89c8</p> <ul> <li>\u672c\u5730\u7aef\u53e3\u6620\u5c04 <ul> <li>\u672c\u5730\u547d\u4ee4\u884c\u8f93\u5165 \uff1a<code>bash ssh -p 48886 root@ssh.intern-ai.org.cn -CNg -L 7860:127.0.0.1:7860 -o StrictHostKeyChecking=no</code></li> <li>\u6ce8\u610f \uff1a\u66ff\u6362\u7aef\u53e3\u4e3a\u81ea\u5df1\u7aef\u53e3\u53f7</li> </ul> </li> <li>\u8bbf\u95ee <code>http://127.0.0.1:7860/</code> </li> </ul> </li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_5","title":"\u53ef\u9009\u4efb\u52a1","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#1-linux","title":"\u2460 Linux\u57fa\u7840\u547d\u4ee4","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_6","title":"\u6587\u4ef6\u7ba1\u7406","text":"<ul> <li>\u521b\u5efa\u6587\u4ef6\uff1a\u53ef\u4ee5\u4f7f\u7528 <code>touch</code> \u547d\u4ee4\u521b\u5efa\u7a7a\u6587\u4ef6\u3002</li> <li>\u521b\u5efa\u76ee\u5f55\uff1a\u4f7f\u7528 <code>mkdir</code> \u547d\u4ee4\u3002</li> <li>\u76ee\u5f55\u5207\u6362\uff1a\u4f7f\u7528<code>cd</code>\u547d\u4ee4\u3002</li> <li>\u663e\u793a\u6240\u5728\u76ee\u5f55\uff1a\u4f7f\u7528<code>pwd</code>\u547d\u4ee4\u3002</li> <li>\u67e5\u770b\u6587\u4ef6\u5185\u5bb9\uff1a\u5982\u4f7f\u7528 <code>cat</code> \u76f4\u63a5\u663e\u793a\u6587\u4ef6\u5168\u90e8\u5185\u5bb9\uff0c<code>more</code> \u548c <code>less</code> \u53ef\u4ee5\u5206\u9875\u67e5\u770b\u3002</li> <li>\u7f16\u8f91\u6587\u4ef6\uff1a\u5982 <code>vi</code> \u6216 <code>vim</code> \u7b49\u7f16\u8f91\u5668\u3002</li> <li>\u590d\u5236\u6587\u4ef6\uff1a\u7528 <code>cp</code> \u547d\u4ee4\u3002</li> <li>\u521b\u5efa\u6587\u4ef6\u94fe\u63a5\uff1a\u7528<code>ln</code>\u547d\u4ee4\u3002</li> <li>\u79fb\u52a8\u6587\u4ef6\uff1a\u901a\u8fc7 <code>mv</code> \u547d\u4ee4\u3002</li> <li>\u5220\u9664\u6587\u4ef6\uff1a\u4f7f\u7528 <code>rm</code> \u547d\u4ee4\u3002</li> <li>\u5220\u9664\u76ee\u5f55\uff1a<code>rmdir</code>\uff08\u53ea\u80fd\u5220\u9664\u7a7a\u76ee\u5f55\uff09\u6216 <code>rm -r</code>\uff08\u53ef\u5220\u9664\u975e\u7a7a\u76ee\u5f55\uff09\u3002</li> <li>\u67e5\u627e\u6587\u4ef6\uff1a\u53ef\u4ee5\u7528 <code>find</code> \u547d\u4ee4\u3002</li> <li>\u67e5\u770b\u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8be6\u7ec6\u4fe1\u606f\uff1a\u4f7f\u7528<code>ls</code>\u547d\u4ee4\uff0c\u5982\u4f7f\u7528 <code>ls -l</code>\u67e5\u770b\u76ee\u5f55\u4e0b\u6587\u4ef6\u7684\u8be6\u7ec6\u4fe1\u606f\u3002</li> <li>\u5904\u7406\u6587\u4ef6\uff1a\u8fdb\u884c\u590d\u6742\u7684\u6587\u4ef6\u64cd\u4f5c\uff0c\u53ef\u4ee5\u4f7f\u7528<code>sed</code>\u547d\u4ee4\u3002</li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_7","title":"\u8fdb\u7a0b\u7ba1\u7406","text":"<p>\u8fdb\u7a0b\u7ba1\u7406\u547d\u4ee4\u662f\u8fdb\u884c\u7cfb\u7edf\u76d1\u63a7\u548c\u8fdb\u7a0b\u7ba1\u7406\u65f6\u7684\u91cd\u8981\u5de5\u5177\uff0c\u5e38\u7528\u7684\u8fdb\u7a0b\u7ba1\u7406\u547d\u4ee4\u6709\u4ee5\u4e0b\u51e0\u79cd\uff1a</p> <ul> <li>ps\uff1a\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u8fdb\u7a0b</li> <li>top\uff1a\u52a8\u6001\u663e\u793a\u6b63\u5728\u8fd0\u884c\u7684\u8fdb\u7a0b</li> <li>pstree\uff1a\u6811\u72b6\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u8fdb\u7a0b</li> <li>pgrep\uff1a\u7528\u4e8e\u67e5\u627e\u8fdb\u7a0b</li> <li>nice\uff1a\u66f4\u6539\u8fdb\u7a0b\u7684\u4f18\u5148\u7ea7</li> <li>jobs\uff1a\u663e\u793a\u8fdb\u7a0b\u7684\u76f8\u5173\u4fe1\u606f</li> <li>bg \u548c fg\uff1a\u5c06\u8fdb\u7a0b\u8c03\u5165\u540e\u53f0</li> <li>kill\uff1a\u6740\u6b7b\u8fdb\u7a0b</li> </ul> <p><code>bash nvidia-smi</code></p> <p></p>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#2-vscode-conda","title":"\u2461 VSCODE \u8fdc\u7a0b\u8fde\u63a5\u5f00\u53d1\u673a\u5e76\u521b\u5efa\u4e00\u4e2aconda\u73af\u5883","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#vscodessh","title":"\u4f7f\u7528VScode\u8fdb\u884cssh\u8fdc\u7a0b\u8fde\u63a5","text":"<ul> <li> <p>Remote-SSH\u63d2\u4ef6</p> <ul> <li>1.\u6253\u5f00\u6269\u5c55\u9762\u677f</li> <li>2.\u641c\u7d22Remote-SSH\u63d2\u4ef6</li> <li>3.\u5b89\u88c5 </li> </ul> </li> <li> <p>ssh\u8fdc\u7a0b\u8fde\u63a5</p> <ul> <li>1.\u6253\u5f00\u547d\u4ee4\u9762\u677f</li> <li>2.\u8f93\u5165ssh\u547d\u4ee4 </li> <li>\u70b9\u51fbconnet\u8fde\u63a5\u4e3b\u673a </li> <li>\u62a5\u9519 <ul> <li>\u9519\u8bef\u89e3\u51b3\uff1avscode\u7248\u672c\u4ece1.87\u5347\u7ea7\u52301.91\uff08\u76f4\u63a5\u4e0b\u8f7d\u6700\u65b0\u7684\u5b89\u88c5\u6587\u4ef6\uff0c\u53cc\u51fb\u5b89\u88c5\u53ef\u89c6\u4e3a\u5347\u7ea7\uff0c\u4e0d\u7528\u62c5\u5fc3\u63d2\u4ef6\u4e22\u5931\uff09 </li> <li>\u9519\u8bef\u7406\u89e3\uff1a\u5f00\u53d1\u673a\u4e2d\u7684vscode\u7248\u672c\u4e3a\u6700\u65b0\uff0c\u7528\u6237\u672c\u5730vscode\u7248\u672c\u4e3a\u65e7\uff0c\u9700\u8981\u66f4\u65b0\u7528\u6237\u672c\u5730vscode\u7248\u672c</li> </ul> </li> <li>\u6253\u5f00\u5f00\u53d1\u673aroot\u6587\u4ef6\u5939 </li> <li>\u521b\u5efa\u4e00\u4e2aconda\u73af\u5883  <ul> <li><code>conda create -n Beginner python=3.10</code></li> </ul> </li> <li>\u8fdb\u5165\u521b\u5efa\u7684conda\u73af\u5883<ul> <li><code>conda activate Beginner</code> </li> </ul> </li> </ul> </li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.1%20Linux%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#3-testsh","title":"\u2462 \u521b\u5efa\u5e76\u8fd0\u884c<code>test.sh</code>\u6587\u4ef6","text":"<pre><code>cd pro/\ntouch test.sh\nvim test.sh\nnvidia-smi\nsh test.sh\n</code></pre>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"1.2 Python \u57fa\u7840\u77e5\u8bc6","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"\u4efb\u52a1\u7c7b\u578b \u4efb\u52a1\u5185\u5bb9 \u9884\u8ba1\u8017\u65f6 \u95ef\u5173\u4efb\u52a1 Python\u5b9e\u73b0wordcount 15mins \u95ef\u5173\u4efb\u52a1 Vscode\u8fde\u63a5InternStudio debug\u7b14\u8bb0 15mins"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#1wordcount","title":"1.wordcount \u4efb\u52a1","text":"<p>\u8bf7\u5b9e\u73b0\u4e00\u4e2awordcount\u51fd\u6570\uff0c\u7edf\u8ba1\u82f1\u6587\u5b57\u7b26\u4e32\u4e2d\u6bcf\u4e2a\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\u3002\u8fd4\u56de\u4e00\u4e2a\u5b57\u5178\uff0ckey\u4e3a\u5355\u8bcd\uff0cvalue\u4e3a\u5bf9\u5e94\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\u3002</p> <p>Eg:</p> <p>Input:</p> <pre><code>\"\"\"Hello world!  \nThis is an example.  \nWord count is fun.  \nIs it fun to count words?  \nYes, it is fun!\"\"\"\n</code></pre> <p>Output:</p> <pre><code>{'hello': 1,'world!': 1,'this': 1,'is': 3,'an': 1,'example': 1,'word': 1, \n'count': 2,'fun': 1,'Is': 1,'it': 2,'to': 1,'words': 1,'Yes': 1,'fun': 1  }\n</code></pre> <p>TIPS\uff1a\u8bb0\u5f97\u5148\u53bb\u6389\u6807\u70b9\u7b26\u53f7,\u7136\u540e\u628a\u6bcf\u4e2a\u5355\u8bcd\u8f6c\u6362\u6210\u5c0f\u5199\u3002\u4e0d\u9700\u8981\u8003\u8651\u7279\u522b\u591a\u7684\u6807\u70b9\u7b26\u53f7\uff0c\u53ea\u9700\u8981\u8003\u8651\u5b9e\u4f8b\u8f93\u5165\u4e2d\u5b58\u5728\u7684\u5c31\u53ef\u4ee5\u3002</p> <pre><code>text = \"\"\"\nGot this panda plush toy for my daughter's birthday,\nwho loves it and takes it everywhere. It's soft and\nsuper cute, and its face has a friendly look. It's\na bit small for what I paid though. I think there\nmight be other options that are bigger for the\nsame price. It arrived a day earlier than expected,\nso I got to play with it myself before I gave it\nto her.\n\"\"\"\n\ndef wordcount(text):\n    pass\n</code></pre>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#2vscodeinternstudio-debug","title":"2.Vscode\u8fde\u63a5InternStudio debug \u4efb\u52a1","text":"<p>\u8bf7\u4f7f\u7528\u672c\u5730vscode\u8fde\u63a5\u8fdc\u7a0b\u5f00\u53d1\u673a\uff0c\u5c06\u4e0a\u9762\u4f60\u5199\u7684wordcount\u51fd\u6570\u5728\u5f00\u53d1\u673a\u4e0a\u8fdb\u884cdebug\uff0c\u4f53\u9a8cdebug\u7684\u5168\u6d41\u7a0b\uff0c\u5e76\u5b8c\u6210\u4e00\u4efddebug\u7b14\u8bb0(\u9700\u8981\u622a\u56fe)\u3002</p>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#wordcount","title":"wordcount\u7ed3\u679c\u63d0\u4ea4","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#debug","title":"debug\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_3","title":"\u4e09\u3001\u4efb\u52a1\u6b65\u9aa4","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#wordcount_1","title":"wordcount","text":"<pre><code>text = \"\"\"\nGot this panda plush toy for my daughter's birthday,\nwho loves it and takes it everywhere. It's soft and\nsuper cute, and its face has a friendly look. It's\na bit small for what I paid though. I think there\nmight be other options that are bigger for the\nsame price. It arrived a day earlier than expected,\nso I got to play with it myself before I gave it\nto her.\n\"\"\"\n\ndef wordcount(text):\n    \"\"\"\n    \u7edf\u8ba1\u7ed9\u5b9a\u82f1\u6587\u5b57\u7b26\u4e32\u4e2d\u6bcf\u4e2a\u5355\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\u3002\n\n    \u53c2\u6570:\n        text (str): \u8f93\u5165\u7684\u82f1\u6587\u5b57\u7b26\u4e32\u3002\n\n    \u8fd4\u56de:\n        dict: \u5b57\u5178\u7c7b\u578b\u7684\u7ed3\u679c\uff0c\u5176\u4e2d\u952e\u662f\u5355\u8bcd\uff0c\u503c\u662f\u8be5\u5355\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\u3002\n    \"\"\"\n\n    # \u5c06\u6240\u6709\u5b57\u7b26\u8f6c\u6362\u4e3a\u5c0f\u5199\uff0c\u4ee5\u4fbf\u7edf\u4e00\u5904\u7406\n    text = text.lower()\n\n    # \u5b9a\u4e49\u4e00\u4e2a\u5b57\u7b26\u4e32\uff0c\u5305\u542b\u6240\u6709\u9700\u8981\u88ab\u79fb\u9664\u7684\u6807\u70b9\u7b26\u53f7\n    punctuation = '''!()-[]{};:'\"\\,&lt;&gt;./?@#$%^&amp;*_~'''\n\n    # \u79fb\u9664\u6240\u6709\u6807\u70b9\u7b26\u53f7\n    for char in text:\n        if char in punctuation:\n            text = text.replace(char, \"\")\n\n    # \u6839\u636e\u7a7a\u683c\u5206\u5272\u5b57\u7b26\u4e32\uff0c\u5f97\u5230\u5355\u8bcd\u5217\u8868\n    words = text.split()\n\n    # \u521d\u59cb\u5316\u4e00\u4e2a\u5b57\u5178\u6765\u5b58\u50a8\u5355\u8bcd\u53ca\u5176\u51fa\u73b0\u6b21\u6570\n    word_count = {}\n\n    # \u904d\u5386\u5355\u8bcd\u5217\u8868\uff0c\u7edf\u8ba1\u6bcf\u4e2a\u5355\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\n    for word in words:\n        if word not in word_count:\n            word_count[word] = 0\n        word_count[word] += 1\n\n    # \u8fd4\u56de\u7edf\u8ba1\u7ed3\u679c\n    return word_count\n\nprint(wordcount(text))\n</code></pre>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.2%20Python%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#vscodeinternstudio-debug","title":"Vscode\u8fde\u63a5InternStudio debug","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.3%20Git%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"1.3 Git\u57fa\u7840","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.3%20Git%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<ul> <li>\u4efb\u52a11: \u7834\u51b0\u6d3b\u52a8\uff1a\u81ea\u6211\u4ecb\u7ecd<ul> <li> <ol> <li>\u547d\u540d\u683c\u5f0f\u4e3a <code>camp3_&lt;id&gt;.md</code>\uff0c\u5176\u4e2d <code>&lt;id&gt;</code> \u662f\u60a8\u7684\u62a5\u540d\u95ee\u5377ID\u3002</li> </ol> </li> <li> <ol> <li>\u6587\u4ef6\u8def\u5f84\u5e94\u4e3a <code>./data/Git/task/</code>\u3002</li> </ol> </li> <li> <ol> <li>\u3010\u5927\u5bb6\u53ef\u4ee5\u53eb\u6211\u3011\u5185\u5bb9\u53ef\u4ee5\u662f GitHub \u6635\u79f0\u3001\u5fae\u4fe1\u6635\u79f0\u6216\u5176\u4ed6\u7f51\u540d\u3002</li> </ol> </li> <li> <ol> <li>\u5728 GitHub \u4e0a\u521b\u5efa\u4e00\u4e2a Pull Request\uff0c\u63d0\u4f9b\u5bf9\u5e94\u7684 PR \u94fe\u63a5\u3002</li> </ol> </li> </ul> </li> <li>\u4efb\u52a12: \u5b9e\u8df5\u9879\u76ee\uff1a\u6784\u5efa\u4e2a\u4eba\u9879\u76ee<ul> <li> <ol> <li>\u521b\u5efa\u5e76\u7ef4\u62a4\u4e00\u4e2a\u516c\u5f00\u7684\u5927\u6a21\u578b\u76f8\u5173\u9879\u76ee\u6216\u7b14\u8bb0\u4ed3\u5e93\u3002</li> </ol> </li> <li> <ol> <li>\u63d0\u4ea4\u4f5c\u4e1a\u65f6\uff0c\u63d0\u4f9b\u60a8\u7684 GitHub \u4ed3\u5e93\u94fe\u63a5\u3002</li> </ol> </li> <li> <ol> <li>\u5982\u679c\u60a8\u4e0d\u5e38\u4f7f\u7528 GitHub\uff0c\u60a8\u53ef\u4ee5\u9009\u62e9\u5176\u4ed6\u4ee3\u7801\u7ba1\u7406\u5e73\u53f0\uff0c\u5982 Gitee\uff0c\u5e76\u63d0\u4ea4\u76f8\u5e94\u7684\u94fe\u63a5\u3002</li> </ol> </li> <li> <ol> <li>\u4ed3\u5e93\u4ecb\u7ecd\u4e2d\u6dfb\u52a0\u8d85\u94fe\u63a5\u8df3\u8f6c GitHub \u4ed3\u5e93\uff08https://github.com/InternLM/Tutorial\uff09</li> </ol> </li> <li> <ol> <li>\u5c06\u6b64\u9879\u76ee\u62a5\u540d\u53c2\u52a0\u7b2c\u4e09\u671f\u5b9e\u6218\u8425\u9879\u76ee\u8bc4\u9009\u5c06\u89e3\u9501 30% A100 \u548c 168 \u56e2\u961f\u7b97\u529b\u70b9\u8d44\u6e90\uff0c\u62a5\u540d\u94fe\u63a5\uff1ahttps://aicarrier.feishu.cn/wiki/DjY6whCO0inTu2kQN9Cchxgynme</li> </ol> </li> </ul> </li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.3%20Git%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":"<ul> <li> <p>PR\u81ea\u6211\u4ecb\u7ecd</p> <ul> <li>\u5408\u5e76\u8bf7\u6c42PR\u94fe\u63a5\uff1ahttps://github.com/InternLM/Tutorial/pull/1044 </li> </ul> </li> <li> <p>\u5b9e\u8df5\u9879\u76ee</p> <ul> <li>\u9879\u76ee\u5730\u5740\uff1ahttps://github.com/acondess/menke </li> </ul> </li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.3%20Git%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_3","title":"\u4e09\u3001\u4efb\u52a1\u5b9e\u73b0\u6b65\u9aa4","text":""},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.3%20Git%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#pull-request","title":"Pull Request\u81ea\u6211\u4ecb\u7ecd","text":"<ul> <li>fork \u4ed3\u5e93 https://github.com/InternLM/Tutorial</li> <li>clone fork \u4ed3\u5e93\u5230\u5f00\u53d1\u673a <code>git clone https://github.com/acondess/Tutorial.git</code> </li> <li>\u67e5\u770b\u5206\u652f <code>git branch -a</code></li> <li>\u5207\u6362\u5206\u652f <code>git checkout -b camp3 origin/camp3</code></li> <li>\u81ea\u5b9a\u4e49\u4e00\u4e2a\u65b0\u7684\u5206\u652f <code>git checkout -b camp3_1858</code> </li> <li>\u521b\u5efa\u81ea\u6211\u4ecb\u7ecd\u6587\u4ef6\uff0c\u6587\u4ef6\u8def\u5f84\u4e3a <code>./data/Git/task/camp3_1858.md</code> </li> <li>\u63d0\u4ea4\u66f4\u6539\u5230\u5206\u652f    <code>git add .</code> <code>git commit -m \"add camp3_1858.md\"</code> <code>git push origin camp3_1858</code> </li> <li>\u8bf7\u6c42\u5408\u5e76\u5230\u4e3b\u5206\u652f  </li> <li>\u6309\u8981\u6c42\u586b\u5199title </li> <li>\u63d0\u4ea4\u6210\u529f </li> <li>\u5408\u5e76\u8bf7\u6c42PR\u94fe\u63a5\uff1ahttps://github.com/InternLM/Tutorial/pull/1044</li> </ul>"},{"location":"%E5%85%A5%E9%97%A8%E5%B2%9B/1.3%20Git%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#_4","title":"\u5b9e\u8df5\u9879\u76ee","text":"<ul> <li> <p>\u9879\u76ee\u767b\u8bb0\u5165\u53e3</p> </li> <li> <p>\u9879\u76ee\u521b\u5efa\u5165\u53e3 </p> </li> <li> <p>\u521b\u5efa\u56e2\u961f     </p> </li> <li> <p>\u521b\u5efagithub\u4ed3\u5e93</p> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/","title":"2.1 \u4e66\u751f\u5927\u6a21\u578b\u5168\u94fe\u8def\u5f00\u6e90\u4f53\u7cfb","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<ul> <li>b\u7ad9\u89c6\u9891</li> <li>\u4e66\u751f\u00b7\u6d66\u8bed</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#_2","title":"\u4ecb\u7ecd","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#1","title":"1. \u5f00\u6e90","text":"<p> - InternLM-7B - InternLM-20B - InternLM2 - InternLM2.5</p> <p></p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#2-internlm25","title":"2. InternLM2.5","text":"<ul> <li>\u5353\u8d8a\u7684\u63a8\u7406\u6027\u80fd\uff1a\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u540c\u91cf\u7ea7\u6a21\u578b\u6700\u4f18\u7cbe\u5ea6\uff0c\u8d85\u8d8a\u4e86 Llama3 \u548c Gemma2-9B\u3002</li> <li>\u6709\u6548\u652f\u6301\u767e\u4e07\u5b57\u8d85\u957f\u4e0a\u4e0b\u6587\uff1a\u6a21\u578b\u5728 1 \u767e\u4e07\u5b57\u957f\u8f93\u5165\u4e2d\u51e0\u4e4e\u5b8c\u7f8e\u5730\u5b9e\u73b0\u957f\u6587\u201c\u5927\u6d77\u635e\u9488\u201d\uff0c\u800c\u4e14\u5728 LongBench \u7b49\u957f\u6587\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e5f\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u4e2d\u7684\u9886\u5148\u6c34\u5e73\u3002 \u53ef\u4ee5\u901a\u8fc7 LMDeploy \u5c1d\u8bd5\u767e\u4e07\u5b57\u8d85\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3002</li> <li>\u5de5\u5177\u8c03\u7528\u80fd\u529b\u6574\u4f53\u5347\u7ea7\uff1aInternLM2.5 \u652f\u6301\u4ece\u4e0a\u767e\u4e2a\u7f51\u9875\u641c\u96c6\u6709\u6548\u4fe1\u606f\u8fdb\u884c\u5206\u6790\u63a8\u7406\u3002</li> <li>InternLM2.5 \u5177\u6709\u66f4\u5f3a\u548c\u66f4\u5177\u6709\u6cdb\u5316\u6027\u7684\u6307\u4ee4\u7406\u89e3\u3001\u5de5\u5177\u7b5b\u9009\u4e0e\u7ed3\u679c\u53cd\u601d\u7b49\u80fd\u529b\uff0c\u65b0\u7248\u6a21\u578b\u53ef\u4ee5\u66f4\u53ef\u9760\u5730\u652f\u6301\u590d\u6742\u667a\u80fd\u4f53\u7684\u642d\u5efa\uff0c\u652f\u6301\u5bf9\u5de5\u5177\u8fdb\u884c\u6709\u6548\u7684\u591a\u8f6e\u8c03\u7528\uff0c\u5b8c\u6210\u8f83\u590d\u6742\u7684\u4efb\u52a1\u3002</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#3","title":"3. \u6838\u5fc3\u6280\u672f\u601d\u8def","text":"<ul> <li>\u6a21\u578b\u80fd\u529b\u98de\u8f6e</li> </ul> <ul> <li>\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#4","title":"4. \u63a8\u7406\u80fd\u529b","text":"<ul> <li>100\u4e07Token \u4e0a\u4e0b\u6587</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#5","title":"5. \u57fa\u4e8e\u89c4\u5212\u548c\u641c\u7d22\u89e3\u51b3\u590d\u6742\u95ee\u9898","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#6","title":"6. \u5f00\u539f\u6a21\u578b\u8c31\u7cfb","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#7","title":"7. \u5168\u94fe\u5f00\u6e90&amp;\u793e\u533a\u751f\u6001","text":"<ul> <li>\u6570\u636e</li> </ul> <ul> <li>\u6570\u636e\u5904\u7406</li> </ul> <ul> <li>\u9884\u8bad\u7ec3\uff08\u5fae\u8c03\u6846\u67b6 XTuner\uff09</li> </ul> <ul> <li>\u6d4b\u8bc4\u4f53\u7cfb OpenCompass</li> </ul> <ul> <li>\u90e8\u7f72 LMDeploy</li> </ul> <ul> <li>\u667a\u80fd\u4f53 </li> </ul> <ul> <li>\u667a\u80fd\u4f53  Lagent</li> </ul> <ul> <li>\u667a\u80fd\u4f53 MindSerch</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.1%20%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB/#8","title":"8. \u4f01\u4e1a\u7ea7\u77e5\u8bc6\u6784\u5efa\u5de5\u5177","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/","title":"2.2 8G \u663e\u5b58\u73a9\u8f6c\u4e66\u751f\u5927\u6a21\u578b Demo","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<p>\u53c2\u8003\u6587\u6863</p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u4f7f\u7528 Cli Demo \u5b8c\u6210 InternLM2-Chat-1.8B \u6a21\u578b\u7684\u90e8\u7f72\uff0c\u5e76\u751f\u6210 300 \u5b57\u5c0f\u6545\u4e8b\uff0c\u8bb0\u5f55\u590d\u73b0\u8fc7\u7a0b\u5e76\u622a\u56fe\u3002</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":"<ul> <li> <p>\u4f7f\u7528 LMDeploy \u5b8c\u6210 InternLM-XComposer2-VL-1.8B \u7684\u90e8\u7f72\uff0c\u5e76\u5b8c\u6210\u4e00\u6b21\u56fe\u6587\u7406\u89e3\u5bf9\u8bdd\uff0c\u8bb0\u5f55\u590d\u73b0\u8fc7\u7a0b\u5e76\u622a\u56fe\u3002</p> </li> <li> <p>\u4f7f\u7528 LMDeploy \u5b8c\u6210 InternVL2-2B \u7684\u90e8\u7f72\uff0c\u5e76\u5b8c\u6210\u4e00\u6b21\u56fe\u6587\u7406\u89e3\u5bf9\u8bdd\uff0c\u8bb0\u5f55\u590d\u73b0\u8fc7\u7a0b\u5e76\u622a\u56fe\u3002</p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u4f7f\u7528 Cli Demo \u5b8c\u6210 InternLM2-Chat-1.8B \u6a21\u578b\u7684\u90e8\u7f72</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":"<ul> <li> <p>\u4f7f\u7528 LMDeploy \u5b8c\u6210 InternLM-XComposer2-VL-1.8B \u7684\u90e8\u7f72</p> <p></p> </li> <li> <p>\u4f7f\u7528 LMDeploy \u5b8c\u6210 InternVL2-2B \u7684\u90e8\u7f72</p> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#internlm2-chat-18b","title":"InternLM2-Chat-1.8B \u6a21\u578b\u7684\u90e8\u7f72","text":"<ul> <li> <p>Step 1 \u521b\u5efa\u865a\u62df\u73af\u5883\u5e76\u8fdb\u5165</p> <p><code>conda create -n demo python=3.10 -y</code></p> <p><code>conda activate demo</code></p> </li> <li> <p>Step2 \u5b89\u88c5torch \u53ca\u76f8\u5173\u4f9d\u8d56</p> <pre><code>    # \u5b89\u88c5 torch\n    conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y\n\n    # \u5b89\u88c5transformers\u5e93\u7684\u6307\u5b9a\u7248\u672c4.38\n    # transformers\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406(NLP)\u5e93\uff0c\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5982BERT, GPT\u7b49\u3002\n    pip install transformers==4.38\n\n    # \u5b89\u88c5sentencepiece\u5e93\u7684\u6307\u5b9a\u7248\u672c0.1.99\n    # sentencepiece\u662f\u4e00\u4e2a\u7528\u4e8e\u6587\u672c\u5206\u8bcd\u7684\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\u6216\u6df7\u5408\u8bed\u8a00\u7684\u6587\u672c\u5904\u7406\u3002\n    pip install sentencepiece==0.1.99\n\n    # \u5b89\u88c5einops\u5e93\u7684\u6307\u5b9a\u7248\u672c0.8.0\n    # einops\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u4fbf\u7684\u65b9\u5f0f\u6765\u64cd\u4f5c\u5f20\u91cf\uff0c\u5c24\u5176\u9002\u5408\u6df1\u5ea6\u5b66\u4e60\u9879\u76ee\u4e2d\u7684\u6570\u636e\u5904\u7406\u3002\n    pip install einops==0.8.0\n\n    # \u5b89\u88c5protobuf\u5e93\u7684\u6307\u5b9a\u7248\u672c5.27.2\n    # protobuf\u662fGoogle\u5f00\u53d1\u7684\u4e00\u79cd\u6570\u636e\u4ea4\u6362\u683c\u5f0f\uff0c\u9ad8\u6548\u4e14\u8de8\u8bed\u8a00\uff0c\u5e38\u7528\u4e8e\u5b9a\u4e49API\u6570\u636e\u7ed3\u6784\u3002\n    pip install protobuf==5.27.2\n\n    # \u5b89\u88c5accelerate\u5e93\u7684\u6307\u5b9a\u7248\u672c0.33.0\n    # accelerate\u5e93\u65e8\u5728\u7b80\u5316\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\n    pip install accelerate==0.33.0\n\n    # \u5b89\u88c5streamlit\u5e93\u7684\u6307\u5b9a\u7248\u672c1.37.0\n    # streamlit\u662f\u4e00\u4e2a\u7528\u4e8e\u5feb\u901f\u6784\u5efa\u548c\u5206\u4eab\u6570\u636e\u5e94\u7528\u7684\u6846\u67b6\uff0c\u975e\u5e38\u9002\u5408\u6570\u636e\u5206\u6790\u548c\u53ef\u89c6\u5316\u9879\u76ee\u3002\n    pip install streamlit==1.37.0\n</code></pre> </li> <li> <p>Step3 \u521b\u5efa\u7f16\u5199demo.py</p> <pre><code>    import torch\n    from transformers import AutoTokenizer, AutoModelForCausalLM\n\n\n    model_name_or_path = \"/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b\"\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='cuda:0')\n    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='cuda:0')\n    model = model.eval()\n\n    system_prompt = \"\"\"You are an AI assistant whose name is InternLM (\u4e66\u751f\u00b7\u6d66\u8bed).\n    - InternLM (\u4e66\u751f\u00b7\u6d66\u8bed) is a conversational language model that is developed by Shanghai AI Laboratory (\u4e0a\u6d77\u4eba\u5de5\u667a\u80fd\u5b9e\u9a8c\u5ba4). It is designed to be helpful, honest, and harmless.\n    - InternLM (\u4e66\u751f\u00b7\u6d66\u8bed) can understand and communicate fluently in the language chosen by the user such as English and \u4e2d\u6587.\n    \"\"\"\n\n    messages = [(system_prompt, '')]\n\n    print(\"=============Welcome to InternLM chatbot, type 'exit' to exit.=============\")\n\n    while True:\n        input_text = input(\"\\nUser  &gt;&gt;&gt; \")\n        input_text = input_text.replace(' ', '')\n        if input_text == \"exit\":\n            break\n\n        length = 0\n        for response, _ in model.stream_chat(tokenizer, input_text, messages):\n            if response is not None:\n                print(response[length:], flush=True, end=\"\")\n                length = len(response)\n</code></pre> </li> <li> <p>Step4 \u8fd0\u884cdemo.py</p> <p><code>python /root/pro/demo.py</code> </p> </li> <li> <p>Step5 Streamlit \u754c\u9762\u90e8\u7f72InternLM2-Chat-1.8B \u6a21\u578b</p> <p>streamlit_demo.py</p> <p><code>streamlit run /root/pro/streamlit_demo.py</code></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#lmdeploy-internlm-xcomposer2-vl-18b","title":"LMDeploy \u90e8\u7f72 InternLM-XComposer2-VL-1.8B \u6a21\u578b","text":"<p>InternLM-XComposer2 \u662f\u4e00\u6b3e\u57fa\u4e8e InternLM2 \u7684\u89c6\u89c9\u8bed\u8a00\u5927\u6a21\u578b\uff0c\u5176\u64c5\u957f\u81ea\u7531\u5f62\u5f0f\u7684\u6587\u672c\u56fe\u50cf\u5408\u6210\u548c\u7406\u89e3\u3002</p> <p>LMDeploy \u662f\u4e00\u4e2a\u7528\u4e8e\u538b\u7f29\u3001\u90e8\u7f72\u548c\u670d\u52a1 LLM \u7684\u5de5\u5177\u5305</p> <ul> <li> <p>Step 1 \u5b89\u88c5lmdeploy\u53ca\u4f9d\u8d56</p> <pre><code>    pip install lmdeploy[all]==0.5.1\n    pip install timm==1.0.7\n</code></pre> </li> <li> <p>Step 2 LMDeploy \u76f4\u63a5\u90e8\u7f72gradio\u5e94\u7528</p> <pre><code>    lmdeploy serve gradio /share/new_models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-1_8b --cache-max-entry-count 0.1\n</code></pre> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#lmdeploy-internvl2-2b","title":"\u4f7f\u7528 LMDeploy \u5b8c\u6210 InternVL2-2B \u7684\u90e8\u7f72","text":"<ul> <li> <p>\u66ff\u6362\u6a21\u578b\u8def\u5f84</p> <pre><code>    lmdeploy serve gradio /share/new_models/OpenGVLab/InternVL2-2B --cache-max-entry-count 0.1\n</code></pre> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.2%208G%20%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%20Demo/#_6","title":"\u603b\u7ed3","text":"<ul> <li> <p>LMDeploy \u662f\u4e00\u4e2a\u7528\u4e8e\u538b\u7f29\u3001\u90e8\u7f72\u548c\u670d\u52a1 LLM \u7684\u5de5\u5177\u5305\uff0c\u53ef\u4ee5\u8f7b\u677e\u5b9e\u73b0\u6a21\u578b\u7684\u538b\u7f29\u3001\u90e8\u7f72\u548c\u53ef\u89c6\u5316\u3002</p> <ul> <li>\u90e8\u7f72internlm2-chat-1_8b\u6a21\u578b \uff1a <code>lmdeploy serve gradio /root/pro/Laboratory/internlm2-chat-1_8b</code></li> </ul> <p></p> </li> <li> <p>github\u5730\u5740 </p> </li> <li> <p>\u6587\u6863\u5730\u5740</p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/","title":"2.3 \u6d66\u8bed\u63d0\u793a\u8bcd\u5de5\u7a0b\u5b9e\u8df5","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<p>\u4efb\u52a1\u5730\u5740</p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u5229\u7528LangGPT\u4f18\u5316\u63d0\u793a\u8bcd\uff0c\u4f7fLLM\u8f93\u51fa\u6b63\u786e\u7ed3\u679c\u3002</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li> <p>\u4f18\u5316\u63d0\u793a\u8bcd</p> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#langgpt","title":"\u5229\u7528LangGPT\u4f18\u5316\u63d0\u793a\u8bcd","text":"<ul> <li> <p>\u6a21\u578b\u53ca\u5e94\u7528\u90e8\u7f72</p> </li> <li> <p>\u63d0\u793a\u8bcd\u5de5\u7a0b</p> </li> <li> <p>\u7ed3\u6784\u5316\u63d0\u793a\u8bcd</p> </li> <li> <p>\u5b9e\u8df5\u63d0\u793a\u8bcd</p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.3%20%E6%B5%A6%E8%AF%AD%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/#_6","title":"\u6a21\u578b\u53ca\u5e94\u7528\u90e8\u7f72","text":"<ul> <li> <p>Step1: \u6a21\u578b\u83b7\u53d6</p> <p>HF\u6a21\u578b\u83b7\u53d6\u4ee3\u7801\uff1a</p> <pre><code>from huggingface_hub import login, snapshot_download\nimport os\n\nos.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n\nlogin(token=\u201cyour_access_token\")\n\nmodels = [\"internlm/internlm2_5-7b-chat\"]\n\nfor model in models:\n    try:\n        snapshot_download(repo_id=model,local_dir=\"path_to_model\")\n    except Exception as e:\n        print(e)\n        pass\n</code></pre> <ul> <li> <p>Huggingface \u79d8\u94a5\u83b7\u53d6</p> <p></p> </li> <li> <p>\u6a21\u578b\u672c\u5730\u5b58\u50a8\u5730\u5740\uff1a</p> <p><code>snapshot_download(repo_id=model,local_dir=\"path_to_model\")</code> </p> </li> </ul> <p></p> </li> <li> <p>Step2: Imdeploy \u90e8\u7f72\u6a21\u578bapi\u670d\u52a1\uff08lmdeploy serve api_server\uff09</p> <p><code>CUDA_VISIBLE_DEVICES=0 lmdeploy serve api_server /share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b --server-port 23333 --api-keys internlm2</code></p> <p></p> </li> <li> <p>Step3: \u8c03\u7528api\u670d\u52a1</p> <ul> <li> <p>\u5b89\u88c5openai\u5e93 <code>pip install openai</code></p> </li> <li> <p>\u7f16\u5199api\u8c03\u7528\u4ee3\u7801</p> </li> </ul> <pre><code>from openai import OpenAI\n\nclient = OpenAI(\n    api_key = \"internlm2\",\n    base_url = \"http://localhost:23333/v1\"\n)\n\nresponse = client.chat.completions.create(\n    model=client.models.list().data[0].id,\n    messages=[\n        {\"role\": \"system\", \"content\": \"\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4f60\u81ea\u5df1\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n</code></pre> <p></p> </li> <li> <p>Step4: Streamlit\u754c\u9762\u5316\u8c03\u7528api\u670d\u52a1</p> <p><code>streamlit run  /root/pro/Tutorial/tools/chat_ui.py</code></p> <p></p> <p></p> </li> <li> <p>\u63d0\u793a\u8bcd</p> <pre><code>- Role: \u6570\u5b66\u6559\u5e08\n- Background: \u7528\u6237\u9700\u8981\u4e00\u4e2a\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e24\u4e2a\u5c0f\u6570\u7684\u5927\u5c0f\uff0c\u5305\u62ec\u6574\u6570\u90e8\u5206\u548c\u5c0f\u6570\u90e8\u5206\u7684\u6bd4\u8f83\u3002\n- Profile: \u60a8\u662f\u4e00\u4f4d\u6570\u5b66\u6559\u5e08\uff0c\u64c5\u957f\u6559\u6388\u548c\u89e3\u91ca\u6570\u5b66\u6982\u5ff5\uff0c\u5305\u62ec\u5c0f\u6570\u7684\u6bd4\u8f83\u3002\n- Skills: \u6570\u5b66\u77e5\u8bc6\u3001\u6559\u5b66\u80fd\u529b\u3001\u903b\u8f91\u63a8\u7406\u3002\n- Goals: \u8bbe\u8ba1\u4e00\u4e2a\u6e05\u6670\u3001\u6613\u61c2\u7684\u6d41\u7a0b\u6765\u6bd4\u8f83\u4e24\u4e2a\u5c0f\u6570\u7684\u5927\u5c0f\u3002\n- Constrains: \u6bd4\u8f83\u65b9\u6cd5\u9700\u8981\u51c6\u786e\u65e0\u8bef\uff0c\u9002\u7528\u4e8e\u6240\u6709\u5c0f\u6570\u7684\u6bd4\u8f83\u3002\n- OutputFormat: \u6b65\u9aa4\u8bf4\u660e\u548c\u793a\u4f8b\u3002\n- Workflow:\n1. \u6bd4\u8f83\u6574\u6570\u90e8\u5206\uff0c\u786e\u5b9a\u54ea\u4e2a\u6574\u6570\u90e8\u5206\u66f4\u5927\u3002\n2. \u5982\u679c\u6574\u6570\u90e8\u5206\u76f8\u540c\uff0c\u6bd4\u8f83\u5c0f\u6570\u90e8\u5206\u7684\u5341\u5206\u4f4d\u3002\n3. \u4f9d\u6b21\u6bd4\u8f83\u5c0f\u6570\u70b9\u540e\u7684\u6bcf\u4e00\u4f4d\uff0c\u76f4\u5230\u627e\u5230\u4e0d\u540c\u7684\u6570\u5b57\u6216\u786e\u5b9a\u4e00\u4e2a\u6570\u66f4\u5927\u3002\n4. \u5982\u679c\u4e00\u4e2a\u6570\u7684\u5c0f\u6570\u90e8\u5206\u4f4d\u6570\u4e0d\u8db3\uff0c\u8ba4\u4e3a\u7f3a\u5931\u7684\u4f4d\u6570\u4e3a0\u3002\n5. \u4e00\u65e6\u786e\u5b9a\u4e00\u4e2a\u6570\u5728\u67d0\u4e00\u4f4d\u4e0a\u66f4\u5927\uff0c\u7ed3\u675f\u6bd4\u8f83\u3002\n- Examples:\n- \u6bd4\u8f833.11\u548c3.8\uff1a\n    - \u6574\u6570\u90e8\u5206\u90fd\u662f3\uff0c\u76f8\u540c\u3002\n    - \u6bd4\u8f83\u5341\u5206\u4f4d\uff0c3.11\u7684\u5341\u5206\u4f4d\u662f1\uff0c3.8\u7684\u5341\u5206\u4f4d\u662f8\uff08\u89c6\u4e3a3.80\uff09\uff0c8 &gt; 1\u3002\n    - \u7ed3\u679c\uff1a3.8 &gt; 3.11\u3002\n- Initialization: \u6b22\u8fce\u4f7f\u7528\u5c0f\u6570\u6bd4\u8f83\u65b9\u6cd5\uff0c\u8ba9\u6211\u4eec\u4e00\u8d77\u5b66\u4e60\u5982\u4f55\u51c6\u786e\u5730\u6bd4\u8f83\u4e24\u4e2a\u5c0f\u6570\u7684\u5927\u5c0f\u3002\u8bf7\u53d1\u9001\u60a8\u60f3\u8981\u6bd4\u8f83\u7684\u4e24\u4e2a\u5c0f\u6570\u3002\n</code></pre> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/","title":"2.4 InternLM + LlamaIndex RAG \u5b9e\u8df5","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<p>\u4efb\u52a1\u5730\u5740</p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u57fa\u4e8e LlamaIndex \u6784\u5efa\u81ea\u5df1\u7684 RAG \u77e5\u8bc6\u5e93</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li> <p>Xxtuner\u662f\u4ec0\u4e48\uff1f</p> <ul> <li> <p>before </p> <p></p> </li> <li> <p>after</p> <p></p> </li> </ul> </li> <li> <p>\u81ea\u5b9a\u4e49\u95ee\u9898\u53ca\u77e5\u8bc6\u5e93</p> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_4","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_5","title":"\u6982\u5ff5","text":"<ul> <li> <p>\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08Retrieval Augmented Generation\uff0cRAG\uff09</p> <ul> <li>RAG \u662f\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u5173\u6700\u77e5\u540d\u7684\u5de5\u5177\u4e4b\u4e00\uff0c\u4ece\u5916\u90e8\u77e5\u8bc6\u5e93\u4e2d\u68c0\u7d22\u4e8b\u5b9e\uff0c\u4ee5\u4fbf\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u63d0\u4f9b\u6700\u51c6\u786e\u3001\u6700\u65b0\u7684\u4fe1\u606f\u3002</li> </ul> </li> <li> <p>\u6e90\u8bcd\u5411\u91cf\u6a21\u578b Sentence Transformer  (a.k.a. SBERT) \u662f\u7528\u4e8e\u8bbf\u95ee\u3001\u4f7f\u7528\u548c\u8bad\u7ec3\u6700\u5148\u8fdb\u7684\u6587\u672c\u548c\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\u7684\u9996\u9009 Python \u6a21\u5757</p> <ul> <li>\u6587\u6863</li> </ul> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_6","title":"\u6b65\u9aa4","text":"<ul> <li> <p>Step1 30% A100 \u5f00\u53d1\u673a\u53ca\u73af\u5883</p> <p></p> </li> <li> <p>Step2 conda \u521b\u5efa\u73af\u5883\u53capytorch\u5b89\u88c5</p> <p><code>conda create -n rag python=3.10</code></p> <p><code>conda activate rag</code></p> <p><code>conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia</code></p> <p><code>pip install einops</code></p> <p><code>pip install  protobuf</code></p> <ul> <li>einops\u662f\u4e00\u4e2aPython\u5e93\uff0c\u63d0\u4f9b\u4e86\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u9ad8\u7ea7\u64cd\u4f5c\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u5bf9\u591a\u7ef4\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\u548c\u53d8\u6362\u3002</li> <li>protobuf\u662fGoogle\u5f00\u53d1\u7684\u4e00\u79cd\u6570\u636e\u5e8f\u5217\u5316\u534f\u8bae\uff0c\u53ef\u4ee5\u5c06\u6570\u636e\u7ed3\u6784\u4ee5\u4e8c\u8fdb\u5236\u683c\u5f0f\u8fdb\u884c\u5e8f\u5217\u5316\u548c\u53cd\u5e8f\u5217\u5316\uff0c\u76f8\u6bd4\u4e8e\u6587\u672c\u683c\u5f0f\u7684\u6570\u636e\u5e8f\u5217\u5316\u65b9\u5f0f\uff08\u5982JSON\uff09\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u6548\u7387\u548c\u66f4\u5c0f\u7684\u4f53\u79ef\u3002</li> </ul> </li> <li> <p>Step3 Llamaindex\u3001transformers\u3001sentence-transformers\u5b89\u88c5</p> <p><code>pip install llama-index==0.10.38 llama-index-llms-huggingface==0.2.0 \"transformers[torch]==4.41.1\" \"huggingface_hub[inference]==0.23.1\" huggingface_hub==0.23.1 sentence-transformers==2.7.0 sentencepiece==0.2.0</code></p> </li> <li> <p>Step4 \u8bcd\u5411\u91cf\u6a21\u578b\u4e0b\u8f7d\uff08paraphrase-multilingual-MiniLM-L12-v2\uff09</p> <p>paraphrase-multilingual-MiniLM-L12-v2 \u5730\u5740</p> <ul> <li>\u521b\u5efaragmodel.py\u6587\u4ef6     <pre><code>import os\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n\n# \u4e0b\u8f7d\u6a21\u578b\nos.system('huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/pro/model/sentence-transformer')\n</code></pre></li> <li> <p>\u6267\u884cragmodel.py\u6587\u4ef6     <code>python /root/pro/ragmodel.py</code></p> <p></p> </li> </ul> <p>huggingface-cli \u4e0b\u8f7d\u9700\u8981\u4f9d\u8d56huggingface_hub</p> </li> <li> <p>Step5 NLTK\u4e0b\u8f7d</p> <p><pre><code>    cd /root\n    git clone https://gitee.com/yzy0612/nltk_data.git  --branch gh-pages\n    cd nltk_data\n    mv packages/*  ./\n    cd tokenizers\n    unzip punkt.zip\n    cd ../taggers\n    unzip averaged_perceptron_tagger.zip\n</code></pre> </p> </li> <li> <p>Step6 \u57fa\u4e8ellamaindex\u5bf9\u8bdd</p> <ul> <li>\u521b\u5efa&amp;\u8fd0\u884cllamaindex_chat.py\u6587\u4ef6</li> </ul> <pre><code>from llama_index.llms.huggingface import HuggingFaceLLM\nfrom llama_index.core.llms import ChatMessage\nllm = HuggingFaceLLM(\n    model_name=\"/root/model/internlm2-chat-1_8b\",\n    tokenizer_name=\"/root/model/internlm2-chat-1_8b\",\n    model_kwargs={\"trust_remote_code\":True},\n    tokenizer_kwargs={\"trust_remote_code\":True}\n)\n\nrsp = llm.chat(messages=[ChatMessage(content=\"xtuner\u662f\u4ec0\u4e48\uff1f\")])\nprint(rsp)\n</code></pre> <p><code>python /root/pro/llamaindex_chat.py</code></p> <p></p> </li> <li> <p>Step7 \u57fa\u4e8ellamaindex\u77e5\u8bc6\u5e93\u5bf9\u8bdd</p> <ul> <li>\u5b89\u88c5embedding\u5e93</li> </ul> <p><code>pip install llama-index-embeddings-huggingface llama-index-embeddings-instructor</code></p> <ul> <li>\u521b\u5efa&amp;\u8fd0\u884cllamaindex_rag.py\u6587\u4ef6</li> </ul> <pre><code>from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface import HuggingFaceLLM\n\n#\u521d\u59cb\u5316\u4e00\u4e2aHuggingFaceEmbedding\u5bf9\u8c61\uff0c\u7528\u4e8e\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u5411\u91cf\u8868\u793a\nembed_model = HuggingFaceEmbedding(\n#\u6307\u5b9a\u4e86\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684sentence-transformer\u6a21\u578b\u7684\u8def\u5f84\n    model_name=\"/root/pro/model/sentence-transformer\"\n)\n#\u5c06\u521b\u5efa\u7684\u5d4c\u5165\u6a21\u578b\u8d4b\u503c\u7ed9\u5168\u5c40\u8bbe\u7f6e\u7684embed_model\u5c5e\u6027\uff0c\n#\u8fd9\u6837\u5728\u540e\u7eed\u7684\u7d22\u5f15\u6784\u5efa\u8fc7\u7a0b\u4e2d\u5c31\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u6a21\u578b\u3002\nSettings.embed_model = embed_model\n\nllm = HuggingFaceLLM(\n    model_name=\"/root/pro/Laboratory/internlm2-chat-1_8b\",\n    tokenizer_name=\"/root/pro/Laboratory/internlm2-chat-1_8b\",\n    model_kwargs={\"trust_remote_code\":True},\n    tokenizer_kwargs={\"trust_remote_code\":True}\n)\n#\u8bbe\u7f6e\u5168\u5c40\u7684llm\u5c5e\u6027\uff0c\u8fd9\u6837\u5728\u7d22\u5f15\u67e5\u8be2\u65f6\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u6a21\u578b\u3002\nSettings.llm = llm\n\n#\u4ece\u6307\u5b9a\u76ee\u5f55\u8bfb\u53d6\u6240\u6709\u6587\u6863\uff0c\u5e76\u52a0\u8f7d\u6570\u636e\u5230\u5185\u5b58\u4e2d\ndocuments = SimpleDirectoryReader(\"/root/pro/XTuner\").load_data()\n#\u521b\u5efa\u4e00\u4e2aVectorStoreIndex\uff0c\u5e76\u4f7f\u7528\u4e4b\u524d\u52a0\u8f7d\u7684\u6587\u6863\u6765\u6784\u5efa\u7d22\u5f15\u3002\n# \u6b64\u7d22\u5f15\u5c06\u6587\u6863\u8f6c\u6362\u4e3a\u5411\u91cf\uff0c\u5e76\u5b58\u50a8\u8fd9\u4e9b\u5411\u91cf\u4ee5\u4fbf\u4e8e\u5feb\u901f\u68c0\u7d22\u3002\nindex = VectorStoreIndex.from_documents(documents)\n# \u521b\u5efa\u4e00\u4e2a\u67e5\u8be2\u5f15\u64ce\uff0c\u8fd9\u4e2a\u5f15\u64ce\u53ef\u4ee5\u63a5\u6536\u67e5\u8be2\u5e76\u8fd4\u56de\u76f8\u5173\u6587\u6863\u7684\u54cd\u5e94\u3002\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"xtuner\u662f\u4ec0\u4e48?\")\n\nprint(response)    \n</code></pre> <p></p> </li> <li> <p>Step8 \u66ff\u6362\u77e5\u8bc6\u5e93\u8fdb\u884c\u5bf9\u5e94\u95ee\u7b54</p> <ul> <li> <p>\u77e5\u8bc6\u5e93github\u5730\u5740 </p> </li> <li> <p>\u4fee\u6539\u4ee3\u7801</p> <ul> <li>llamaindex_chat.py <pre><code>rsp = llm.chat(messages=[ChatMessage(content=\"\u8bf7\u4ecb\u7ecdllm-universe \")])\n</code></pre></li> <li>llamaindex_rag.py <pre><code>documents = SimpleDirectoryReader(\"/root/pro/llm-universe\").load_data() \n</code></pre></li> </ul> </li> <li>\u6267\u884cllamaindex_chat.py\u53callamaindex_rag.py </li> </ul> </li> <li> <p>Step9 webui</p> <ul> <li> <p>\u5b89\u88c5streamlit <code>pip install streamlit</code></p> </li> <li> <p>\u521b\u5efa&amp;\u8fd0\u884cllamaindexwebui.py\u6587\u4ef6</p> </li> </ul> <pre><code>import streamlit as st\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface import HuggingFaceLLM\n\nst.set_page_config(page_title=\"llama_index_demo\", page_icon=\"\ud83e\udd9c\ud83d\udd17\")\nst.title(\"llama_index_demo\")\n\n# \u521d\u59cb\u5316\u6a21\u578b\n@st.cache_resource\ndef init_models():\n    embed_model = HuggingFaceEmbedding(\n        model_name=\"/root/pro/model/sentence-transformer\"\n    )\n    Settings.embed_model = embed_model\n\n    llm = HuggingFaceLLM(\n        model_name=\"/root/pro/Laboratory/internlm2-chat-1_8b\",\n        tokenizer_name=\"/root/pro/Laboratory/internlm2-chat-1_8b\",\n        model_kwargs={\"trust_remote_code\": True},\n        tokenizer_kwargs={\"trust_remote_code\": True}\n    )\n    Settings.llm = llm\n\n    documents = SimpleDirectoryReader(\"/root/pro/llm-universe\").load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    query_engine = index.as_query_engine()\n\n    return query_engine\n\n# \u68c0\u67e5\u662f\u5426\u9700\u8981\u521d\u59cb\u5316\u6a21\u578b\nif 'query_engine' not in st.session_state:\n    st.session_state['query_engine'] = init_models()\n\ndef greet2(question):\n    response = st.session_state['query_engine'].query(question)\n    return response\n\n\n# Store LLM generated responses\nif \"messages\" not in st.session_state.keys():\n    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"\u4f60\u597d\uff0c\u6211\u662f\u4f60\u7684llm-universe\u5b66\u4e60\u52a9\u624b\uff0c\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u52a9\u4f60\u7684\u5417\uff1f\"}]    \n\n    # Display or clear chat messages\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.write(message[\"content\"])\n\ndef clear_chat_history():\n    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"\u4f60\u597d\uff0c\u6211\u662f\u4f60\u7684llm-universe\u52a9\u624b\uff0c\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u52a9\u4f60\u7684\u5417\uff1f\"}]\n\nst.sidebar.button('Clear Chat History', on_click=clear_chat_history)\n\n# Function for generating LLaMA2 response\ndef generate_llama_index_response(prompt_input):\n    return greet2(prompt_input)\n\n# User-provided prompt\nif prompt := st.chat_input():\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    with st.chat_message(\"user\"):\n        st.write(prompt)\n\n# Gegenerate_llama_index_response last message is not from assistant\nif st.session_state.messages[-1][\"role\"] != \"assistant\":\n    with st.chat_message(\"assistant\"):\n        with st.spinner(\"Thinking...\"):\n            response = generate_llama_index_response(prompt)\n            placeholder = st.empty()\n            placeholder.markdown(response)\n    message = {\"role\": \"assistant\", \"content\": response}\n    st.session_state.messages.append(message)\n</code></pre> <ul> <li>\u6267\u884cllamaindexwebui.py</li> </ul> <p><code>streamlit run /root/pro/llamaindexwebui.py</code></p> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#_7","title":"\u56db\u3001 \u6269\u5c55","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#41-embedding","title":"4.1 embedding\u6a21\u578b","text":"<ul> <li>Sentence Transformer</li> <li>Huggingface of Sentence Transformer</li> <li>ollama nomic-embed-text</li> <li>\u6392\u884c\u699c</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#42-llamaindex","title":"4.2 LlamaIndex","text":"<ul> <li>LlamaIndex github</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.4%20InternLM%20%2B%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5/#43-rag","title":"4.3 \u66ff\u6362RAG\u6a21\u578b\u5b9e\u6218","text":"<ul> <li> <p>\u4e0b\u8f7dEmbedding\u6a21\u578b</p> <ul> <li> <p>\u6a21\u578b\u5730\u5740\uff1a    lier007/xiaobu-embedding-v2</p> </li> <li> <p>\u6a21\u578b\u4e0b\u8f7d\uff1a  xiaobu.py</p> </li> </ul> <pre><code>import os\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n\n# \u4e0b\u8f7d\u6a21\u578b\nos.system('huggingface-cli download --resume-download lier007/xiaobu-embedding-v2 --local-dir /root/pro/model/xiaobu-embedding-v2')\n</code></pre> <p></p> </li> <li> <p>\u66ff\u6362RAG\u6a21\u578b</p> <ul> <li>llamaindex_rag_xiaobu.py</li> </ul> <pre><code>from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface import HuggingFaceLLM\n\n#\u521d\u59cb\u5316\u4e00\u4e2aHuggingFaceEmbedding\u5bf9\u8c61\uff0c\u7528\u4e8e\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u5411\u91cf\u8868\u793a\nembed_model = HuggingFaceEmbedding(\n#\u6307\u5b9a\u4e86\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684sentence-transformer\u6a21\u578b\u7684\u8def\u5f84\n    model_name=\"/root/pro/model/xiaobu-embedding-v2\"\n)\n#\u5c06\u521b\u5efa\u7684\u5d4c\u5165\u6a21\u578b\u8d4b\u503c\u7ed9\u5168\u5c40\u8bbe\u7f6e\u7684embed_model\u5c5e\u6027\uff0c\n#\u8fd9\u6837\u5728\u540e\u7eed\u7684\u7d22\u5f15\u6784\u5efa\u8fc7\u7a0b\u4e2d\u5c31\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u6a21\u578b\u3002\nSettings.embed_model = embed_model\n\nllm = HuggingFaceLLM(\n    model_name=\"/root/pro/Laboratory/internlm2-chat-1_8b\",\n    tokenizer_name=\"/root/pro/Laboratory/internlm2-chat-1_8b\",\n    model_kwargs={\"trust_remote_code\":True},\n    tokenizer_kwargs={\"trust_remote_code\":True}\n)\n#\u8bbe\u7f6e\u5168\u5c40\u7684llm\u5c5e\u6027\uff0c\u8fd9\u6837\u5728\u7d22\u5f15\u67e5\u8be2\u65f6\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u6a21\u578b\u3002\nSettings.llm = llm\n\n#\u4ece\u6307\u5b9a\u76ee\u5f55\u8bfb\u53d6\u6240\u6709\u6587\u6863\uff0c\u5e76\u52a0\u8f7d\u6570\u636e\u5230\u5185\u5b58\u4e2d\n# documents = SimpleDirectoryReader(\"/root/pro/XTuner\").load_data()\ndocuments = SimpleDirectoryReader(\"/root/pro/llm-universe\").load_data()\n#\u521b\u5efa\u4e00\u4e2aVectorStoreIndex\uff0c\u5e76\u4f7f\u7528\u4e4b\u524d\u52a0\u8f7d\u7684\u6587\u6863\u6765\u6784\u5efa\u7d22\u5f15\u3002\n# \u6b64\u7d22\u5f15\u5c06\u6587\u6863\u8f6c\u6362\u4e3a\u5411\u91cf\uff0c\u5e76\u5b58\u50a8\u8fd9\u4e9b\u5411\u91cf\u4ee5\u4fbf\u4e8e\u5feb\u901f\u68c0\u7d22\u3002\nindex = VectorStoreIndex.from_documents(documents)\n# \u521b\u5efa\u4e00\u4e2a\u67e5\u8be2\u5f15\u64ce\uff0c\u8fd9\u4e2a\u5f15\u64ce\u53ef\u4ee5\u63a5\u6536\u67e5\u8be2\u5e76\u8fd4\u56de\u76f8\u5173\u6587\u6863\u7684\u54cd\u5e94\u3002\nquery_engine = index.as_query_engine()\n# response = query_engine.query(\"xtuner\u662f\u4ec0\u4e48?\")\nresponse = query_engine.query(\"\u8bf7\u4ecb\u7ecdllm-universe\u7684\u8bfe\u7a0b\u5927\u7eb2 \")\n\nprint(response)\n</code></pre> <p></p> </li> <li> <p>\u66ff\u6362\u57fa\u7840\u5927\u6a21\u578b(Qwen2-7B-Instruct)</p> <pre><code>llm = HuggingFaceLLM(\nmodel_name=\"/root/share/new_models/qwen/Qwen2-7B-Instruct\",\ntokenizer_name=\"/root/share/new_models/qwen/Qwen2-7B-Instruct\",\nmodel_kwargs={\"trust_remote_code\":True},\ntokenizer_kwargs={\"trust_remote_code\":True}\n)\n</code></pre> <p></p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/","title":"2.5 XTuner \u5fae\u8c03\u4e2a\u4eba\u5c0f\u52a9\u624b\u8ba4\u77e5","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":"<p>\u53c2\u8003\uff1aXTuner\u5fae\u8c03\u524d\u7f6e\u57fa\u7840</p> <p>\u8fdb\u9636\u53c2\u8003\uff1a XTuner\u5fae\u8c03\u9ad8\u7ea7\u8fdb\u9636</p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u4f7f\u7528 XTuner \u5fae\u8c03 InternLM2-Chat-1.8B \u5b9e\u73b0\u81ea\u5df1\u7684\u5c0f\u52a9\u624b\u8ba4\u77e5</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":"<ul> <li>\u7528\u81ea\u5df1\u611f\u5174\u8da3\u7684\u77e5\u8bc6\u5bf9\u57fa\u5ea7\u6a21\u578b\u8fdb\u884c\u589e\u91cf\u9884\u8bad\u7ec3\u5fae\u8c03\uff08\u9009\u505a\uff09</li> <li>\u5728\u8d44\u6e90\u5141\u8bb8\u7684\u60c5\u51b5\u4e0b\uff0c\u5c1d\u8bd5\u5b9e\u73b0\u591a\u5361\u5fae\u8c03\u4e0e\u5206\u5e03\u5f0f\u5fae\u8c03\uff08\u9009\u505a\uff09</li> <li>\u5c06\u81ea\u6211\u8ba4\u77e5\u7684\u6a21\u578b\u4e0a\u4f20\u5230 OpenXLab\uff0c\u5e76\u5c06\u5e94\u7528\u90e8\u7f72\u5230 OpenXLab\uff08\u4f18\u79c0\u5b66\u5458\u5fc5\u505a\uff09</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":"<ul> <li> <p>\u4f7f\u7528 XTuner \u5fae\u8c03 InternLM2-Chat-1.8B</p> <p></p> </li> <li> <p>\u5c06\u81ea\u6211\u8ba4\u77e5\u7684\u6a21\u578b\u4e0a\u4f20\u5230 OpenXLab\uff0c\u5e76\u5c06\u5e94\u7528\u90e8\u7f72\u5230 OpenXLab</p> </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/#_3","title":"\u4e09\u3001\u4efb\u52a1\u6b65\u9aa4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.5%20XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5/#1-xtuner","title":"1. XTuner \u5fae\u8c03","text":"<p>XTuner \u4e00\u4e2a\u5927\u8bed\u8a00\u6a21\u578b&amp;\u591a\u6a21\u6001\u6a21\u578b\u5fae\u8c03\u5de5\u5177\u7bb1\u3002</p> <ol> <li> <p>\u6253\u5f00\u5f00\u53d1\u673a\u4f7f\u7528\u672c\u5730VScode\u8fdc\u7a0b\u8fde\u63a5</p> <p>\u53c2\u8003\uff1a\u5165\u95e8\u5c9b</p> <p></p> </li> <li> <p>\u521b\u5efa\u53ca\u8fdb\u5165\u865a\u62df\u73af\u5883</p> <p><pre><code># studio-conda -t &lt;target-conda-name&gt; -o &lt;origin-conda-name&gt; \n# \u5c06\u9884\u8bbe\u7684internlm-base\u73af\u5883\u62f7\u8d1d\u5230\u6307\u5b9a\u7684conda\u73af\u5883\uff0c\u547d\u540d\u4e3axtuner\nstudio-conda -t xtuner -o internlm-base\nconda activate xtuner\n</code></pre> </p> </li> <li> <p>\u5b89\u88c5Xturner</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u76ee\u5f55\uff0c\u7528\u6765\u5b58\u653e\u6e90\u4ee3\u7801\nmkdir -p /root/pro\n\ncd /root/pro\n\ngit clone -b v0.1.23  https://github.com/InternLM/XTuner\n\ncd /root/pro/XTuner\n\n# \u5b89\u88c5X\npip install -e '.[deepspeed]'\n\n# \u9a8c\u8bc1\nxtuner version\n</code></pre> <p></p> </li> <li> <p>\u57fa\u5ea7\u6a21\u578b InternLM2-Chat-1.8B     <pre><code>mkdir -p /root/pro/Laboratory\nln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b /root/pro/Laboratory/internlm2-chat-1_8b\n</code></pre> </p> </li> <li> <p>\u751f\u6210\u6570\u636e\u96c6     <pre><code>mkdir -p datas\ntouch datas/assistant.json\n</code></pre></p> <p>```python linenums=1     # \u6821\u672c\u5316\u5199\u5165\u6570\u636e     import json</p> <pre><code># \u8bbe\u7f6e\u7528\u6237\u7684\u540d\u5b57\nname = '\u95e8\u5ba2er'\n# \u8bbe\u7f6e\u9700\u8981\u91cd\u590d\u6dfb\u52a0\u7684\u6570\u636e\u6b21\u6570\nn =  4650\n\n# \u521d\u59cb\u5316\u6570\u636e\ndata = [\n    {\"conversation\": [{\"input\": \"\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4f60\u81ea\u5df1\", \"output\": \"\u6211\u662f{}\u7684\u5c0f\u52a9\u624b\uff0c\u5185\u5728\u662f\u4e0a\u6d77AI\u5b9e\u9a8c\u5ba4\u4e66\u751f\u00b7\u6d66\u8bed\u76841.8B\u5927\u6a21\u578b\u54e6\".format(name)}]},\n    {\"conversation\": [{\"input\": \"\u4f60\u5728\u5b9e\u6218\u8425\u505a\u4ec0\u4e48\", \"output\": \"\u6211\u5728\u8fd9\u91cc\u5e2e\u52a9{}\u5b8c\u6210XTuner\u5fae\u8c03\u4e2a\u4eba\u5c0f\u52a9\u624b\u7684\u4efb\u52a1\".format(name)}]}\n]\n\n# \u901a\u8fc7\u5faa\u73af\uff0c\u5c06\u521d\u59cb\u5316\u7684\u5bf9\u8bdd\u6570\u636e\u91cd\u590d\u6dfb\u52a0\u5230data\u5217\u8868\u4e2d\nfor i in range(n):\n    data.append(data[0])\n    data.append(data[1])\n\n# \u5c06data\u5217\u8868\u4e2d\u7684\u6570\u636e\u5199\u5165\u5230'datas/assistant.json'\u6587\u4ef6\u4e2d\nwith open('datas/assistant.json', 'w', encoding='utf-8') as f:\n    # \u4f7f\u7528json.dump\u65b9\u6cd5\u5c06\u6570\u636e\u4ee5JSON\u683c\u5f0f\u5199\u5165\u6587\u4ef6\n    # ensure_ascii=False \u786e\u4fdd\u4e2d\u6587\u5b57\u7b26\u6b63\u5e38\u663e\u793a\n    # indent=4 \u4f7f\u5f97\u6587\u4ef6\u5185\u5bb9\u683c\u5f0f\u5316\uff0c\u4fbf\u4e8e\u9605\u8bfb\n    json.dump(data, f, ensure_ascii=False, indent=4)\n</code></pre> <p><code></code> bash linenums=1     python xtuner_generate_assistant.py ``` </p> </li> <li> <p>\u67e5\u627e\u914d\u7f6e\u6587\u4ef6</p> <p>XTuner \u63d0\u4f9b\u591a\u4e2a\u5f00\u7bb1\u5373\u7528\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b\u3002</p> <p><code>xtuner list-cfg</code>  \u547d\u4ee4\u7528\u4e8e\u5217\u51fa\u5185\u7f6e\u7684\u6240\u6709\u914d\u7f6e\u6587\u4ef6\u3002\u53c2\u6570 <code>-p</code> \u6216 <code>--pattern</code> \u8868\u793a\u6a21\u5f0f\u5339\u914d\uff0c\u540e\u9762\u8ddf\u7740\u7684\u5185\u5bb9\u5c06\u4f1a\u5728\u6240\u6709\u7684\u914d\u7f6e\u6587\u4ef6\u91cc\u8fdb\u884c\u6a21\u7cca\u5339\u914d\u641c\u7d22\uff0c\u7136\u540e\u8fd4\u56de\u6700\u6709\u53ef\u80fd\u5f97\u5185\u5bb9\u3002\u6bd4\u5982\u6211\u4eec\u8fd9\u91cc\u5fae\u8c03\u7684\u662f\u4e66\u751f\u00b7\u6d66\u8bed\u7684\u6a21\u578b\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5339\u914d\u641c\u7d22 internlm2\u3002</p> <p><code>xtuner list-cfg -p internlm2</code></p> <p> \u76f8\u5173\u914d\u7f6e\u6587\u4ef6 <pre><code>    ==========================CONFIGS===========================\n    PATTERN: internlm2\n    -------------------------------\n    internlm2_1_8b_full_alpaca_e3\n    internlm2_1_8b_full_custom_pretrain_e1\n    internlm2_1_8b_qlora_alpaca_e3\n    internlm2_20b_full_custom_pretrain_e1\n    internlm2_20b_full_finetune_custom_dataset_e1\n    internlm2_20b_qlora_alpaca_e3\n    internlm2_20b_qlora_arxiv_gentitle_e3\n    internlm2_20b_qlora_code_alpaca_e3\n    internlm2_20b_qlora_colorist_e5\n    internlm2_20b_qlora_lawyer_e3\n    internlm2_20b_qlora_msagent_react_e3_gpu8\n    internlm2_20b_qlora_oasst1_512_e3\n    internlm2_20b_qlora_oasst1_e3\n    internlm2_20b_qlora_sql_e3\n    internlm2_5_chat_7b_full_finetune_custom_dataset_e1\n    internlm2_5_chat_7b_qlora_alpaca_e3\n    internlm2_5_chat_7b_qlora_oasst1_e3\n    internlm2_7b_full_custom_pretrain_e1\n    internlm2_7b_full_finetune_custom_dataset_e1\n    internlm2_7b_full_finetune_custom_dataset_e1_sequence_parallel_4\n    internlm2_7b_qlora_alpaca_e3\n    internlm2_7b_qlora_arxiv_gentitle_e3\n    internlm2_7b_qlora_code_alpaca_e3\n    internlm2_7b_qlora_colorist_e5\n    internlm2_7b_qlora_json_e3\n    internlm2_7b_qlora_lawyer_e3\n    internlm2_7b_qlora_msagent_react_e3_gpu8\n    internlm2_7b_qlora_oasst1_512_e3\n    internlm2_7b_qlora_oasst1_e3\n    internlm2_7b_qlora_sql_e3\n    internlm2_7b_w_internevo_dataset\n    internlm2_7b_w_tokenized_dataset\n    internlm2_7b_w_untokenized_dataset\n    internlm2_chat_1_8b_dpo_full\n    internlm2_chat_1_8b_dpo_full_varlenattn\n    internlm2_chat_1_8b_dpo_full_varlenattn_jsonl_dataset\n    internlm2_chat_1_8b_full_alpaca_e3\n    internlm2_chat_1_8b_orpo_full\n    internlm2_chat_1_8b_orpo_full_varlenattn\n    internlm2_chat_1_8b_orpo_full_varlenattn_jsonl_dataset\n    internlm2_chat_1_8b_qlora_alpaca_e3\n    internlm2_chat_1_8b_qlora_custom_sft_e1\n    internlm2_chat_1_8b_reward_full_ultrafeedback\n    internlm2_chat_1_8b_reward_full_varlenattn_jsonl_dataset\n    internlm2_chat_1_8b_reward_full_varlenattn_ultrafeedback\n    internlm2_chat_1_8b_reward_qlora_varlenattn_ultrafeedback\n    internlm2_chat_20b_full_finetune_custom_dataset_e1\n    internlm2_chat_20b_qlora_alpaca_e3\n    internlm2_chat_20b_qlora_code_alpaca_e3\n    internlm2_chat_20b_qlora_custom_sft_e1\n    internlm2_chat_20b_qlora_lawyer_e3\n    internlm2_chat_20b_qlora_oasst1_512_e3\n    internlm2_chat_20b_qlora_oasst1_e3\n    internlm2_chat_7b_dpo_qlora_varlenattn\n    internlm2_chat_7b_full_finetune_custom_dataset_e1\n    internlm2_chat_7b_orpo_qlora_varlenattn_ultrafeedback_e5\n    internlm2_chat_7b_qlora_alpaca_e3\n    internlm2_chat_7b_qlora_code_alpaca_e3\n    internlm2_chat_7b_qlora_custom_sft_e1\n    internlm2_chat_7b_qlora_lawyer_e3\n    internlm2_chat_7b_qlora_oasst1_512_e3\n    internlm2_chat_7b_qlora_oasst1_e3\n    internvl_v1_5_internlm2_26b_finetune\n    internvl_v1_5_internlm2_26b_lora_finetune\n    internvl_v1_5_internlm2_26b_qlora_finetune\n    internvl_v1_5_internlm2_2b_finetune\n    internvl_v1_5_internlm2_2b_lora_finetune\n    internvl_v1_5_internlm2_2b_qlora_finetune\n    internvl_v2_internlm2_26b_finetune\n    internvl_v2_internlm2_26b_lora_finetune\n    internvl_v2_internlm2_26b_qlora_finetune\n    internvl_v2_internlm2_2b_finetune\n    internvl_v2_internlm2_2b_lora_finetune\n    internvl_v2_internlm2_2b_qlora_finetune\n    internvl_v2_internlm2_5_8b_finetune\n    internvl_v2_internlm2_5_8b_lora_finetune\n    internvl_v2_internlm2_5_8b_qlora_finetune\n    llava_internlm2_chat_1_8b_clip_vit_large_p14_336_e1_gpu8_pretrain\n    llava_internlm2_chat_1_8b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune\n    llava_internlm2_chat_20b_clip_vit_large_p14_336_e1_gpu8_finetune\n    llava_internlm2_chat_20b_clip_vit_large_p14_336_e1_gpu8_pretrain\n    llava_internlm2_chat_20b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune\n    llava_internlm2_chat_7b_clip_vit_large_p14_336_e1_gpu8_finetune\n    llava_internlm2_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain\n    llava_internlm2_chat_7b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune\n    =============================================================\n</code></pre> </p> </li> <li> <p>\u590d\u5236&amp;\u4fee\u6539\u914d\u7f6e\u6587\u4ef6 internlm2_chat_1_8b_qlora_alpaca_e3</p> <pre><code> xtuner copy-cfg internlm2_chat_1_8b_qlora_alpaca_e3 .\n</code></pre> <ul> <li> <p>\u4fee\u6539\u6a21\u578b\u4e3a\u672c\u5730\u6a21\u578b\u8def\u5f84 ```python linenums=1 pretrained_model_name_or_path = '/root/pro/Laboratory/internlm2-chat-1_8b' <pre><code>- \u4fee\u6539\u6570\u636e\u96c6\u8def\u5f84\n```python linenums=1\nalpaca_en_path = '/root/pro/datas/assistant.json'\n</code></pre></p> </li> <li> <p>\u4fee\u6539evaluation_inputs ``` bash linenums=1 evaluation_inputs = [ '\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4f60\u81ea\u5df1', 'Please introduce yourself' ] <pre><code>- \u4fee\u6539\u6570\u636e\u96c6\u52a0\u8f7d\u65b9\u5f0f\n```python linenums=1\ndataset=dict(type=load_dataset, path='json', data_files=dict(train=alpaca_en_path)),\n</code></pre></p> </li> <li> <p>\u4fee\u6539\u6570\u636e\u5bf9\u65b9\u5f0f</p> <ul> <li>\u5bf9\u8bdd\u5185\u5bb9\u5df2\u7ecf\u662f input \u548c output \u7684\u6570\u636e\u5bf9\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u8fdb\u884c\u683c\u5f0f\u8f6c\u6362\u3002</li> </ul> </li> </ul> <p><code>python linenums=1 dataset_map_fn=None,</code></p> </li> <li> <p>\u542f\u52a8\u5fae\u8c03</p> <p><code>xtuner train</code> \u547d\u4ee4\u7528\u4e8e\u542f\u52a8\u6a21\u578b\u5fae\u8c03\u8fdb\u7a0b\u3002\u8be5\u547d\u4ee4\u9700\u8981\u4e00\u4e2a\u53c2\u6570\uff1a<code>CONFIG</code>\u7528\u4e8e\u6307\u5b9a\u5fae\u8c03\u914d\u7f6e\u6587\u4ef6\u3002\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4fee\u6539\u597d\u7684\u914d\u7f6e\u6587\u4ef6 <code>internlm2_chat_1_8b_qlora_alpaca_e3_copy.py</code>\u3002</p> <p>\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u6240\u6709\u6587\u4ef6\uff0c\u5305\u62ec\u65e5\u5fd7\u3001\u914d\u7f6e\u6587\u4ef6\u3001\u68c0\u67e5\u70b9\u6587\u4ef6\u3001\u5fae\u8c03\u540e\u7684\u6a21\u578b\u7b49\uff0c\u9ed8\u8ba4\u4fdd\u5b58\u5728 <code>work_dirs</code> \u76ee\u5f55\u4e0b\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6dfb\u52a0 <code>--work-dir</code> \u6307\u5b9a\u7279\u5b9a\u7684\u6587\u4ef6\u4fdd\u5b58\u4f4d\u7f6e\u3002</p> <p><code>bash linenums=1 xtuner train ./internlm2_chat_1_8b_qlora_alpaca_e3_copy.py</code></p> <p></p> <p></p> </li> <li> <p>\u6a21\u578b\u683c\u5f0f\u8f6c\u6362</p> <p>\u6a21\u578b\u8f6c\u6362\u7684\u672c\u8d28\u5176\u5b9e\u5c31\u662f\u5c06\u539f\u672c\u4f7f\u7528 Pytorch \u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u6743\u91cd\u6587\u4ef6\u8f6c\u6362\u4e3a\u76ee\u524d\u901a\u7528\u7684 HuggingFace \u683c\u5f0f\u6587\u4ef6</p> <p><code>xtuner convert pth_to_hf</code> \u547d\u4ee4\u7528\u4e8e\u8fdb\u884c\u6a21\u578b\u683c\u5f0f\u8f6c\u6362\u3002\u8be5\u547d\u4ee4\u9700\u8981\u4e09\u4e2a\u53c2\u6570\uff1a<code>CONFIG</code> \u8868\u793a\u5fae\u8c03\u7684\u914d\u7f6e\u6587\u4ef6\uff0c <code>PATH_TO_PTH_MODEL</code> \u8868\u793a\u5fae\u8c03\u7684\u6a21\u578b\u6743\u91cd\u6587\u4ef6\u8def\u5f84\uff0c\u5373\u8981\u8f6c\u6362\u7684\u6a21\u578b\u6743\u91cd\uff0c <code>SAVE_PATH_TO_HF_MODEL</code> \u8868\u793a\u8f6c\u6362\u540e\u7684 <code>HuggingFace</code> \u683c\u5f0f\u6587\u4ef6\u7684\u4fdd\u5b58\u8def\u5f84\u3002</p> <p><code>bash linenums=1 pth_file=`ls -t ./work_dirs/internlm2_chat_1_8b_qlora_alpaca_e3_copy/*.pth | head -n 1` &amp;&amp; MKL_SERVICE_FORCE_INTEL=1 MKL_THREADING_LAYER=GNU xtuner convert pth_to_hf ./internlm2_chat_1_8b_qlora_alpaca_e3_copy.py ${pth_file} ./hf</code> </p> </li> <li> <p>\u6a21\u578b\u5408\u5e76</p> <p>hf \u6587\u4ef6\u5939\u5373\u4e3a\u6211\u4eec\u5e73\u65f6\u6240\u7406\u89e3\u7684\u6240\u8c13 \u201cLoRA \u6a21\u578b\u6587\u4ef6\u201d</p> <p>\u53ef\u4ee5\u7b80\u5355\u7406\u89e3\uff1aLoRA \u6a21\u578b\u6587\u4ef6 = Adapter</p> <p>\u5bf9\u4e8e LoRA \u6216\u8005 QLoRA \u5fae\u8c03\u51fa\u6765\u7684\u6a21\u578b\u5176\u5b9e\u5e76\u4e0d\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\uff0c\u800c\u662f\u4e00\u4e2a\u989d\u5916\u7684\u5c42\uff08Adapter\uff09\uff0c\u8bad\u7ec3\u5b8c\u7684\u8fd9\u4e2a\u5c42\u6700\u7ec8\u8fd8\u662f\u8981\u4e0e\u539f\u6a21\u578b\u8fdb\u884c\u5408\u5e76\u624d\u80fd\u88ab\u6b63\u5e38\u7684\u4f7f\u7528\u3002</p> <p>\u5bf9\u4e8e\u5168\u91cf\u5fae\u8c03\u7684\u6a21\u578b\uff08full\uff09\u5176\u5b9e\u662f\u4e0d\u9700\u8981\u8fdb\u884c\u6574\u5408\u8fd9\u4e00\u6b65\u7684\uff0c\u56e0\u4e3a\u5168\u91cf\u5fae\u8c03\u4fee\u6539\u7684\u662f\u539f\u6a21\u578b\u7684\u6743\u91cd\u800c\u975e\u5fae\u8c03\u4e00\u4e2a\u65b0\u7684 Adapter \uff0c\u56e0\u6b64\u662f\u4e0d\u9700\u8981\u8fdb\u884c\u6a21\u578b\u6574\u5408\u7684\u3002</p> <p>xtuner convert merge\u547d\u4ee4\u7528\u4e8e\u5408\u5e76\u6a21\u578b\u3002\u8be5\u547d\u4ee4\u9700\u8981\u4e09\u4e2a\u53c2\u6570\uff1aLLM \u8868\u793a\u539f\u6a21\u578b\u8def\u5f84\uff0cADAPTER \u8868\u793a Adapter \u5c42\u7684\u8def\u5f84\uff0c SAVE_PATH \u8868\u793a\u5408\u5e76\u540e\u7684\u6a21\u578b\u6700\u7ec8\u7684\u4fdd\u5b58\u8def\u5f84\u3002</p> <p><code>bash linenums=1 MKL_SERVICE_FORCE_INTEL=1 MKL_THREADING_LAYER=GNU xtuner convert merge /root/pro/Laboratory/internl m2-chat-1_8b ./hf ./merged --max-shard-size 2GB</code></p> <p></p> </li> <li> <p>\u547d\u4ee4\u884c\u5fae\u8c03\u6a21\u578b\u5bf9\u8bdd</p> <ul> <li> <p>\u8fdb\u5165python\u73af\u5883\u8fd0\u884c     <code>bash linenums=1     python</code></p> </li> <li> <p>\u5bfc\u5165\u5e93     <pre><code>import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n</code></pre></p> </li> <li> <p>\u5b9a\u4e49\u52a0\u8f7d\u6a21\u578b\u65b9\u6cd5</p> <p><code>python linenums=1 def load_model(model_path): tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True) model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, trust_remote_code=True).cuda() model = model.eval() return tokenizer, model</code></p> </li> <li> <p>\u5b9a\u4e49\u5bf9\u8bdd\u65b9\u6cd5     ```python linenums=1     messages = []</p> <p>def chat(input_text):     length = 0     for response, _ in model.stream_chat(tokenizer, input_text, messages):         if response is not None:             print(response[length:], flush=True, end=\"\")             length = len(response) ```</p> </li> <li> <p>\u52a0\u8f7d\u5fae\u8c03\u6a21\u578b     <code>python linenums=1     tokenizer, model = load_model(\"/root/pro/merged\")</code></p> </li> <li> <p>\u8fd0\u884c\u5bf9\u8bdd     <code>python linenums=1     chat(\"\u8bf7\u4ecb\u7ecd\u4e00\u4e0b\u4f60\u81ea\u5df1\")     chat(\"\u4f60\u5728\u5b9e\u6218\u8425\u505a\u4ec0\u4e48\uff1f\")</code></p> </li> <li> <p>\u5bf9\u8bdd\u7ed3\u679c</p> <p></p> </li> <li> <p>\u91ca\u653e\u7f13\u5b58</p> <p>```python linenums=1 del tokenizer, model</p> <p>torch.cuda.empty_cache() ```</p> </li> </ul> </li> <li> <p>UI\u754c\u9762\u90e8\u7f72</p> <ul> <li> <p>\u5b89\u88c5streamlit     <code>bash linenums=1     pip install streamlit==1.36.0</code></p> </li> <li> <p>\u7f16\u5199streamlit\u7a0b\u5e8f</p> </li> <li> <p>\u8fd0\u884cstreamlit\u7a0b\u5e8f</p> <ul> <li> <p>\u62a5\u9519</p> <p> issue</p> <p>GenerationMixin._get_logits_warper() missing 1 required positional argument: 'device'</p> </li> </ul> </li> </ul> </li> </ol>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/","title":"2.6 OpenCompass \u8bc4\u6d4b InternLM-1.8B \u5b9e\u8df5","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<p>\u4f7f\u7528 OpenCompass \u8bc4\u6d4b internlm2-chat-1.8b \u6a21\u578b\u5728 ceval \u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u8bb0\u5f55\u590d\u73b0\u8fc7\u7a0b\u5e76\u622a\u56fe\u3002</p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":"<ul> <li>\u4f7f\u7528 OpenCompass \u8fdb\u884c\u4e3b\u89c2\u8bc4\u6d4b\uff08\u9009\u505a\uff09</li> <li>\u4f7f\u7528 OpenCompass \u8bc4\u6d4b InternLM2-Chat-1.8B \u6a21\u578b\u4f7f\u7528 LMDeploy\u90e8\u7f72\u540e\u5728 ceval \u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff08\u9009\u505a\uff09</li> <li>\u4f7f\u7528 OpenCompass \u8fdb\u884c\u8c03\u7528API\u8bc4\u6d4b\uff08\u4f18\u79c0\u5b66\u5458\u5fc5\u505a\uff09</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u547d\u4ee4\u884c\u53c2\u6570\u6cd5</li> </ul> <ul> <li>\u914d\u7f6e\u6587\u4ef6\u53c2\u6570\u6cd5 </li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":"<p>\u5728 OpenCompass \u4e2d\u8bc4\u4f30\u4e00\u4e2a\u6a21\u578b\u901a\u5e38\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u9636\u6bb5\uff1a\u914d\u7f6e -&gt; \u63a8\u7406 -&gt; \u8bc4\u4f30 -&gt; \u53ef\u89c6\u5316\u3002</p> <ul> <li>\u914d\u7f6e\uff1a\u8fd9\u662f\u6574\u4e2a\u5de5\u4f5c\u6d41\u7684\u8d77\u70b9\u3002\u60a8\u9700\u8981\u914d\u7f6e\u6574\u4e2a\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u9009\u62e9\u8981\u8bc4\u4f30\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u8fd8\u53ef\u4ee5\u9009\u62e9\u8bc4\u4f30\u7b56\u7565\u3001\u8ba1\u7b97\u540e\u7aef\u7b49\uff0c\u5e76\u5b9a\u4e49\u663e\u793a\u7ed3\u679c\u7684\u65b9\u5f0f\u3002</li> <li>\u63a8\u7406\u4e0e\u8bc4\u4f30\uff1a\u5728\u8fd9\u4e2a\u9636\u6bb5\uff0cOpenCompass \u5c06\u4f1a\u5f00\u59cb\u5bf9\u6a21\u578b\u548c\u6570\u636e\u96c6\u8fdb\u884c\u5e76\u884c\u63a8\u7406\u548c\u8bc4\u4f30\u3002\u63a8\u7406\u9636\u6bb5\u4e3b\u8981\u662f\u8ba9\u6a21\u578b\u4ece\u6570\u636e\u96c6\u4ea7\u751f\u8f93\u51fa\uff0c\u800c\u8bc4\u4f30\u9636\u6bb5\u5219\u662f\u8861\u91cf\u8fd9\u4e9b\u8f93\u51fa\u4e0e\u6807\u51c6\u7b54\u6848\u7684\u5339\u914d\u7a0b\u5ea6\u3002\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u4f1a\u88ab\u62c6\u5206\u4e3a\u591a\u4e2a\u540c\u65f6\u8fd0\u884c\u7684\u201c\u4efb\u52a1\u201d\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u8bf7\u6ce8\u610f\uff0c\u5982\u679c\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\uff0c\u8fd9\u79cd\u7b56\u7565\u53ef\u80fd\u4f1a\u4f7f\u8bc4\u6d4b\u53d8\u5f97\u66f4\u6162\u3002\u5982\u679c\u9700\u8981\u4e86\u89e3\u8be5\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u53c2\u8003 FAQ: \u6548\u7387\u3002</li> <li>\u53ef\u89c6\u5316\uff1a\u8bc4\u4f30\u5b8c\u6210\u540e\uff0cOpenCompass \u5c06\u7ed3\u679c\u6574\u7406\u6210\u6613\u8bfb\u7684\u8868\u683c\uff0c\u5e76\u5c06\u5176\u4fdd\u5b58\u4e3a CSV \u548c TXT \u6587\u4ef6\u3002\u4f60\u4e5f\u53ef\u4ee5\u6fc0\u6d3b\u98de\u4e66\u72b6\u6001\u4e0a\u62a5\u529f\u80fd\uff0c\u6b64\u540e\u53ef\u4ee5\u5728\u98de\u4e66\u5ba2\u6237\u7aef\u4e2d\u53ca\u65f6\u83b7\u5f97\u8bc4\u6d4b\u72b6\u6001\u62a5\u544a\u3002 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u5c55\u793a OpenCompass \u7684\u57fa\u7840\u7528\u6cd5\uff0c\u5c55\u793a\u4e66\u751f\u6d66\u8bed\u5728 C-Eval \u57fa\u51c6\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u3002\u5b83\u4eec\u7684\u914d\u7f6e\u6587\u4ef6\u53ef\u4ee5\u5728 configs/eval_demo.py \u4e2d\u627e\u5230\u3002</li> </ul>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#31","title":"3.1 \u73af\u5883\u914d\u7f6e","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#311","title":"3.1.1 \u5f00\u53d1\u673a\u521b\u5efa","text":"<p>\u5728\u521b\u5efa\u5f00\u53d1\u673a\u754c\u9762\u9009\u62e9\u955c\u50cf\u4e3a Cuda11.7-conda\uff0c\u5e76\u9009\u62e9 GPU \u4e3a10% A100\u3002</p> <p></p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#312-conda","title":"3.1.2 conda\u73af\u5883\u3001\u6e90\u7801\u53ca\u4f9d\u8d56\u5b89\u88c5","text":"<p><pre><code>conda create -n opencompass python=3.10\nconda activate opencompass\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y\n\n# \u6ce8\u610f\uff1a\u4e00\u5b9a\u8981\u5148 cd /root\ncd /root\ngit clone -b 0.2.4 https://github.com/open-compass/opencompass\ncd opencompass\npip install -e .\n\n\napt-get update\napt-get install cmake\npip install -r requirements.txt\npip install protobuf\n</code></pre> </p> <p></p> <p></p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#32","title":"3.2 \u6570\u636e","text":"<ul> <li>\u62f7\u8d1d\u89e3\u538b\u5f00\u53d1\u673a\u63d0\u4f9b\u7684\u6570\u636e</li> </ul> <pre><code>cp /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/\nunzip OpenCompassData-core-20231110.zip\n</code></pre> <ul> <li>\u67e5\u770b\u652f\u6301\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b</li> </ul> <pre><code>python tools/list_configs.py internlm ceval\n</code></pre>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#33","title":"3.3 \u542f\u52a8\u6d4b\u8bc4","text":""},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#331","title":"3.3.1 \u4f7f\u7528\u547d\u4ee4\u884c\u914d\u7f6e\u53c2\u6570\u6cd5\u8fdb\u884c\u8bc4\u6d4b","text":"<ul> <li>\u6253\u5f00 opencompass\u6587\u4ef6\u5939\u4e0bconfigs/models/hf_internlm/\u7684hf_internlm2_chat_1_8b.py ,\u8d34\u5165\u4ee5\u4e0b\u4ee3\u7801</li> </ul> <p><pre><code>from opencompass.models import HuggingFaceCausalLM\n\n\nmodels = [\n    dict(\n        type=HuggingFaceCausalLM,\n        abbr='internlm2-1.8b-hf',\n        path=\"/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b\",\n        tokenizer_path='/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b',\n        model_kwargs=dict(\n            trust_remote_code=True,\n            device_map='auto',\n        ),\n        tokenizer_kwargs=dict(\n            padding_side='left',\n            truncation_side='left',\n            use_fast=False,\n            trust_remote_code=True,\n        ),\n        max_out_len=100,\n        min_out_len=1,\n        max_seq_len=2048,\n        batch_size=8,\n        run_cfg=dict(num_gpus=1, num_procs=1),\n    )\n]\n</code></pre> - \u914d\u7f6e\u73af\u5883\u53c2\u6570</p> <pre><code>#\u73af\u5883\u53d8\u91cf\u914d\u7f6e\nexport MKL_SERVICE_FORCE_INTEL=1\n#\u6216\nexport MKL_THREADING_LAYER=GNU\n</code></pre> <p></p> <ul> <li>\u8fd0\u884c\u8bc4\u6d4b</li> </ul> <pre><code>python run.py --datasets ceval_gen --models hf_internlm2_chat_1_8b --debug\n</code></pre> <ul> <li>\u547d\u4ee4\u89e3\u6790 <pre><code>python run.py\n--datasets ceval_gen \\ # \u6570\u636e\u96c6\u51c6\u5907\n--models hf_internlm2_chat_1_8b \\  # \u6a21\u578b\u51c6\u5907\n--debug\n</code></pre></li> </ul> <p></p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#332","title":"3.3.2 \u4f7f\u7528\u914d\u7f6e\u6587\u4ef6\u6539\u53c2\u6570\u6cd5\u8fdb\u884c\u8bc4\u6d4b","text":"<p>\u9664\u4e86\u901a\u8fc7\u547d\u4ee4\u884c\u914d\u7f6e\u5b9e\u9a8c\u5916\uff0cOpenCompass \u8fd8\u5141\u8bb8\u7528\u6237\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u7f16\u5199\u5b9e\u9a8c\u7684\u5b8c\u6574\u914d\u7f6e\uff0c\u5e76\u901a\u8fc7 run.py \u76f4\u63a5\u8fd0\u884c\u5b83\u3002\u914d\u7f6e\u6587\u4ef6\u662f\u4ee5 Python \u683c\u5f0f\u7ec4\u7ec7\u7684\uff0c\u5e76\u4e14\u5fc5\u987b\u5305\u62ec datasets \u548c models \u5b57\u6bb5\u3002\u672c\u6b21\u6d4b\u8bd5\u914d\u7f6e\u5728 configs\u6587\u4ef6\u5939 \u4e2d\u3002\u6b64\u914d\u7f6e\u901a\u8fc7 \u7ee7\u627f\u673a\u5236 \u5f15\u5165\u6240\u9700\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\u914d\u7f6e\uff0c\u5e76\u4ee5\u6240\u9700\u683c\u5f0f\u7ec4\u5408 datasets \u548c models \u5b57\u6bb5\u3002 \u8fd0\u884c\u4ee5\u4e0b\u4ee3\u7801\uff0c\u5728configs\u6587\u4ef6\u5939\u4e0b\u521b\u5efaeval_tutorial_demo.py</p> <pre><code>cd /root/opencompass/configs\ntouch eval_tutorial_demo.py\n</code></pre> <p><pre><code>from mmengine.config import read_base\n\nwith read_base():\n    from .datasets.ceval.ceval_gen import ceval_datasets\n    from .models.hf_internlm.hf_internlm2_chat_1_8b import models as hf_internlm2_chat_1_8b_models\n\ndatasets = ceval_datasets\nmodels = hf_internlm2_chat_1_8b_models\n</code></pre> <pre><code>cd /root/opencompass\npython run.py configs/eval_tutorial_demo.py --debug\n</code></pre></p> <p></p>"},{"location":"%E5%9F%BA%E7%A1%80%E5%B2%9B/2.6%20OpenCompass%20%E8%AF%84%E6%B5%8B%20InternLM-1.8B%20%E5%AE%9E%E8%B7%B5/#34","title":"3.4 \u6d4b\u8bc4\u7ed3\u679c","text":"<ul> <li>\u547d\u4ee4\u884c\u53c2\u6570\u6cd5</li> </ul> <ul> <li>\u914d\u7f6e\u6587\u4ef6\u53c2\u6570\u6cd5 </li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/","title":"3.1\u63a2\u7d22 InternLM \u6a21\u578b\u80fd\u529b\u8fb9\u754c","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<p>\u5728 CompassArena \u4e2d\u9009\u62e9\u53cc\u6a21\u578b\u5bf9\u8bdd\uff0c\u4e0eInternLM2.5\u53ca\u53e6\u5916\u4efb\u610f\u5176\u4ed6\u6a21\u578b\u5bf9\u8bdd\uff0c\u6536\u96c6 5 \u4e2a InternLM2.5 \u8f93\u51fa\u7ed3\u679c\u4e0d\u5982\u5176\u4ed6\u6a21\u578b\u7684\u5bf9\u8bdd\u6848\u4f8b\uff0c\u4ee5\u53ca InternLM2.5 \u7684 5 \u4e2a Good Case</p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>Good case 1\uff1a </li> </ul> \u8981\u6c42 \u5185\u5bb9 \u6a21\u578b\u670d\u52a1\u6765\u6e90 compassarea \u60a8\u7684\u8f93\u5165 \u9c81\u8fc5\u4e3a\u4ec0\u4e48\u66b4\u6253\u5468\u6811\u4eba\uff1f \u4e2d\u6587\u56de\u7b54 \u6a21\u578bA internlm2.5-20b-chat \u6a21\u578bB Llama3-8B-Instruct (Meta) \u6a21\u578bA\u8f93\u51fa \u8fd9\u4e2a\u95ee\u9898\u5176\u5b9e\u662f\u4e00\u4e2a\u8bef\u89e3\u3002\"\u9c81\u8fc5\"\u5e76\u975e\u4e00\u4e2a\u4eba\uff0c\u800c\u662f\u5468\u6811\u4eba\u7684\u7b14\u540d\u3002\u5468\u6811\u4eba\u662f\u4ed6\u7684\u539f\u540d\uff0c\u800c\"\u9c81\u8fc5\"\u5219\u662f\u4ed6\u5728\u6587\u5b66\u521b\u4f5c\u4e2d\u4f7f\u7528\u7684\u5316\u540d\u3002\"\u9c81\u8fc5\"\u8fd9\u4e2a\u540d\u5b57\u7684\u6765\u6e90\u6709\u7740\u6df1\u523b\u7684\u5bd3\u610f\u3002\"\u9c81\"\u53d6\u81ea\u4ed6\u7684\u5bb6\u4e61\u6d59\u6c5f\u7701\u7ecd\u5174\u5e02\u7684\u53e4\u79f0\"\u9c81\u56fd\"\uff0c\"\u8fc5\"\u5219\u610f\u5473\u7740\u8fc5\u901f\u6216\u654f\u6377\uff0c\u8c61\u5f81\u4ed6\u5e0c\u671b\u4ee5\u5c16\u9510\u7280\u5229\u7684\u7b14\u89e6\uff0c\u8fc5\u901f\u5524\u8d77\u6c11\u4f17\u7684\u89c9\u9192\u3002\u4ed6\u7684\u4f5c\u54c1\uff0c\u5982\u300a\u72c2\u4eba\u65e5\u8bb0\u300b\u3001\u300a\u963fQ\u6b63\u4f20\u300b\u7b49\uff0c\u63ed\u793a\u4e86\u793e\u4f1a\u7684\u4e0d\u516c\u4e0e\u4eba\u6027\u7684\u5f31\u70b9\uff0c\u5bf9\u4e2d\u56fd\u73b0\u4ee3\u6587\u5b66\u7684\u53d1\u5c55\u4ea7\u751f\u4e86\u6df1\u8fdc\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\"\u9c81\u8fc5\u4e3a\u4ec0\u4e48\u66b4\u6253\u5468\u6811\u4eba\"\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u8d28\u4e0a\u662f\u5bf9\u9c81\u8fc5\u4e0e\u5468\u6811\u4eba\u5173\u7cfb\u7684\u8bef\u89e3\u3002\u4ed6\u4eec\u5b9e\u9645\u4e0a\u662f\u540c\u4e00\u4eba\uff0c\u9c81\u8fc5\u662f\u5468\u6811\u4eba\u7684\u7b14\u540d\uff0c\u7528\u4ee5\u8868\u8fbe\u4ed6\u5bf9\u793e\u4f1a\u95ee\u9898\u7684\u654f\u9510\u6d1e\u5bdf\u529b\u548c\u6df1\u523b\u601d\u8003\u529b\u3002 \u6a21\u578bB\u8f93\u51fa \u6211\u8ba4\u4e3a\u4f60\u53ef\u80fd\u8bef\u89e3\u4e86\u9c81\u8fc5\u548c\u5468\u6811\u4eba\u7684\u5173\u7cfb\u3002\u9c81\u8fc5\u5e76\u6ca1\u6709\u66b4\u6253\u5468\u6811\u4eba\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5468\u6811\u4eba\u662f\u4e00\u4e2a\u8f83\u4e3a\u4e0d\u4e3a\u4eba\u77e5\u7684\u5386\u53f2\u4eba\u7269\uff0c\u6211\u65e0\u6cd5\u627e\u5230\u4efb\u4f55\u5173\u4e8e\u9c81\u8fc5\u548c\u5468\u6811\u4eba\u7684physical altercation\u7684\u4fe1\u606f\u3002\u9c81\u8fc5\u662f\u4e00\u4f4d\u4e2d\u56fd\u8457\u540d\u7684\u4f5c\u5bb6\u3001\u8bd7\u4eba\u548c\u6587\u5b66\u6279\u8bc4\u5bb6\uff0c\u4ed6\u7684\u4f5c\u54c1\u548c\u6279\u8bc4\u5bf9\u4e2d\u56fd\u6587\u5b66\u548c\u793e\u4f1a\u4ea7\u751f\u4e86\u6df1\u8fdc\u7684\u5f71\u54cd\u3002\u4ed6\u662f\u4e00\u4e2a\u6fc0\u8fdb\u7684\u793e\u4f1a\u6539\u9769\u5bb6\uff0c\u4f5c\u54c1\u4e2d\u5e38\u5e38\u63a2\u8ba8\u793e\u4f1a\u6b63\u4e49\u3001\u9053\u5fb7\u548c\u4eba\u7c7b\u95ee\u9898\u3002\u5982\u679c\u4f60\u6709\u66f4\u591a\u7684\u80cc\u666f\u4fe1\u606f\u6216\u53ef\u4ee5\u63d0\u4f9b\u66f4\u591a\u7684\u4e0a\u4e0b\u6587\uff0c\u6211\u5c06\u5c3d\u529b\u5e2e\u52a9\u4f60\u4e86\u89e3\u8fd9\u4e2a\u95ee\u9898\u3002 \u5176\u4ed6\u8865\u5145 Llama3-8B-Instruct (Meta) \u5728\u63d0\u793a\u8bcd\u4e2d\u6ca1\u6709\u660e\u786e\u4e2d\u6587\u56de\u7b54\u7684\u8bdd\uff0c\u4f1a\u4f7f\u7528\u82f1\u6587\u56de\u7b54"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.1%20%E6%8E%A2%E7%B4%A2%20InternLM%20%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E8%BE%B9%E7%95%8C/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/","title":"3.2 Lagent \u81ea\u5b9a\u4e49\u4f60\u7684 Agent \u667a\u80fd\u4f53","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u4f7f\u7528 Lagent \u81ea\u5b9a\u4e49\u4e00\u4e2a\u667a\u80fd\u4f53\uff0c\u5e76\u4f7f\u7528 Lagent Web Demo \u6210\u529f\u90e8\u7f72\u4e0e\u8c03\u7528\uff0c\u8bb0\u5f55\u590d\u73b0\u8fc7\u7a0b\u5e76\u622a\u56fe\u3002</li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u590d\u73b0\u6b65\u9aa4</li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#31","title":"3.1 \u73af\u5883\u914d\u7f6e","text":"<p>\u5f00\u53d1\u673a\u9009\u62e9 30% A100\uff0c\u955c\u50cf\u9009\u62e9\u4e3a Cuda12.2-conda\u3002</p> <pre><code># \u521b\u5efa\u73af\u5883\nconda create -n agent_camp3 python=3.10 -y\n# \u6fc0\u6d3b\u73af\u5883\nconda activate agent_camp3\n# \u5b89\u88c5 torch\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y\n# \u5b89\u88c5\u5176\u4ed6\u4f9d\u8d56\u5305\npip install termcolor==2.4.0\npip install lmdeploy==0.5.2\n</code></pre>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#32-lagent","title":"3.2 lagent\u6e90\u7801\u5b89\u88c5","text":"<pre><code># \u521b\u5efa\u76ee\u5f55\u4ee5\u5b58\u653e\u4ee3\u7801\nmkdir -p /root/agent_camp3\ncd /root/agent_camp3\ngit clone https://github.com/InternLM/lagent.git\ncd lagent &amp;&amp; git checkout 81e7ace &amp;&amp; pip install -e . &amp;&amp; cd ..\n</code></pre>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#33-lagent-web-ui","title":"3.3 lagent web UI","text":"<ul> <li>LMDeploy \u90e8\u7f72 InternLM2.5-7B-Chat\uff0c\u542f\u52a8\u4e00\u4e2a API Server\u3002</li> </ul> <pre><code>conda activate agent_camp3\nlmdeploy serve api_server /share/new_models/Shanghai_AI_Laboratory/internlm2_5-7b-chat --model-name internlm2_5-7b-chat\n</code></pre> <ul> <li>\u53e6\u542f\u4e00\u4e2a\u7a97\u53e3\uff0c\u8fd0\u884c Lagent \u7684 Web Demo\u3002</li> </ul> <pre><code>cd /root/agent_camp3/lagent\nconda activate agent_camp3\nstreamlit run examples/internlm2_agent_web_demo.py\n</code></pre>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#34","title":"3.4 \u672c\u5730\u8bbf\u95ee\u9a8c\u8bc1","text":"<ul> <li>\u7aef\u53e3\u6620\u5c04</li> </ul> <pre><code>ssh -CNg -L 8501:127.0.0.1:8501 -L 23333:127.0.0.1:23333 root@ssh.intern-ai.org.cn -p &lt;\u4f60\u7684 SSH \u7aef\u53e3\u53f7&gt;\n</code></pre> <ul> <li>\u8bbf\u95ee Web Demo</li> </ul> <p>\u5728\u672c\u5730\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 localhost:8501\uff0c\u5e76\u4fee\u6539\u6a21\u578b\u540d\u79f0\u4e00\u680f\u4e3a internlm2_5-7b-chat\uff0c\u4fee\u6539\u6a21\u578b ip\u4e00\u680f\u4e3a127.0.0.1:23333\uff0c\u9009\u62e9\u63d2\u4ef6\u4e3a ArxivSeerch.</p> <p></p> <p>\u8f93\u5165\u63d0\u793a\u8bcd\uff1a<code>\u641c\u7d22Mindsearch\u76f8\u5173\u8bba\u6587</code> </p> <p></p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.2%20Lagent%20%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BD%A0%E7%9A%84%20Agent%20%E6%99%BA%E8%83%BD%E4%BD%93/#35-lagent","title":"3.5  lagent\u81ea\u5b9a\u4e49\u667a\u80fd\u4f53","text":"<ul> <li>\u521b\u5efa\u5de5\u5177\u6587\u4ef6magicmaker.py</li> </ul> <p><pre><code>cd /root/agent_camp3/lagent\ntouch lagent/actions/magicmaker.py\n</code></pre> - \u7f16\u5199magicmaker.py</p> <pre><code>import json\nimport requests\n\nfrom lagent.actions.base_action import BaseAction, tool_api\nfrom lagent.actions.parser import BaseParser, JsonParser\nfrom lagent.schema import ActionReturn, ActionStatusCode\n\n\nclass MagicMaker(BaseAction):\n    styles_option = [\n        'dongman',  # \u52a8\u6f2b\n        'guofeng',  # \u56fd\u98ce\n        'xieshi',   # \u5199\u5b9e\n        'youhua',   # \u6cb9\u753b\n        'manghe',   # \u76f2\u76d2\n    ]\n    aspect_ratio_options = [\n        '16:9', '4:3', '3:2', '1:1',\n        '2:3', '3:4', '9:16'\n    ]\n\n    def __init__(self,\n                 style='guofeng',\n                 aspect_ratio='4:3'):\n        super().__init__()\n        if style in self.styles_option:\n            self.style = style\n        else:\n            raise ValueError(f'The style must be one of {self.styles_option}')\n\n        if aspect_ratio in self.aspect_ratio_options:\n            self.aspect_ratio = aspect_ratio\n        else:\n            raise ValueError(f'The aspect ratio must be one of {aspect_ratio}')\n\n    @tool_api\n    def generate_image(self, keywords: str) -&gt; dict:\n        \"\"\"Run magicmaker and get the generated image according to the keywords.\n\n        Args:\n            keywords (:class:`str`): the keywords to generate image\n\n        Returns:\n            :class:`dict`: the generated image\n                * image (str): path to the generated image\n        \"\"\"\n        try:\n            response = requests.post(\n                url='https://magicmaker.openxlab.org.cn/gw/edit-anything/api/v1/bff/sd/generate',\n                data=json.dumps({\n                    \"official\": True,\n                    \"prompt\": keywords,\n                    \"style\": self.style,\n                    \"poseT\": False,\n                    \"aspectRatio\": self.aspect_ratio\n                }),\n                headers={'content-type': 'application/json'}\n            )\n        except Exception as exc:\n            return ActionReturn(\n                errmsg=f'MagicMaker exception: {exc}',\n                state=ActionStatusCode.HTTP_ERROR)\n        image_url = response.json()['data']['imgUrl']\n        return {'image': image_url}\n</code></pre> <ul> <li> <p>\u9002\u914d\u6211\u4eec\u7684\u81ea\u5b9a\u4e49\u5de5\u5177</p> <ul> <li>\u4fee\u6539 /root/agent_camp3/lagent/examples/internlm2_agent_web_demo.py</li> </ul> <p></p> <ul> <li>\u91cd\u65b0\u8fd0\u884csteamlit \u547d\u4ee4 <code>streamlit run examples/internlm2_agent_web_demo.py</code>,\u914d\u7f6e\u5de5\u5177\u540d\u79f0\u4e3amagicmaker\uff0c\u4fee\u6539\u6a21\u578b\u540d\u79f0\u4e3ainternlm2_5-7b-chat\uff0c\u4fee\u6539\u6a21\u578b ip\u4e00\u680f\u4e3a127.0.0.1:23333\uff0c\u8f93\u5165\u63d0\u793a\u8bcd\uff1a<code>\u5e2e\u6211\u751f\u6210\u4e00\u526f\u6cb9\u753b\u7684\u94a2\u94c1\u4fa0</code></li> </ul> <p></p> <ul> <li>\u591a\u63d2\u4ef6\u6d4b\u8bd5</li> </ul> <p></p> </li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/","title":"3.3 LMDeploy \u91cf\u5316\u90e8\u7f72\u8fdb\u9636\u5b9e\u8df5","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li>\u4f7f\u7528\u7ed3\u5408W4A16\u91cf\u5316\u4e0ekv cache\u91cf\u5316\u7684internlm2_5-7b-chat\u6a21\u578b\u5c01\u88c5\u672c\u5730API\u5e76\u4e0e\u5927\u6a21\u578b\u8fdb\u884c\u4e00\u6b21\u5bf9\u8bdd\uff0c\u4f5c\u4e1a\u622a\u56fe\u9700\u5305\u62ec\u663e\u5b58\u5360\u7528\u60c5\u51b5\u4e0e\u5927\u6a21\u578b\u56de\u590d\uff0c\u53c2\u80034.1 API\u5f00\u53d1(\u4f18\u79c0\u5b66\u5458\u5fc5\u505a)</li> </ul> <ul> <li>\u4f7f\u7528Function call\u529f\u80fd\u8ba9\u5927\u6a21\u578b\u5b8c\u6210\u4e00\u6b21\u7b80\u5355\u7684\"\u52a0\"\u4e0e\"\u4e58\"\u51fd\u6570\u8c03\u7528\uff0c\u4f5c\u4e1a\u622a\u56fe\u9700\u5305\u62ec\u5927\u6a21\u578b\u56de\u590d\u7684\u5de5\u5177\u8c03\u7528\u60c5\u51b5\uff0c\u53c2\u80034.2 Function call(\u9009\u505a)</li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":"<ul> <li> <p>W4A16\u91cf\u5316\u4e0ekv cache\u91cf\u5316\u7684internlm2_5-7b-chat\u663e\u5b58\u5360\u7528\u60c5\u51b5\u4e0e\u5927\u6a21\u578b\u56de\u590d</p> </li> <li> <p>Function call\u529f\u80fd\u8ba9\u5927\u6a21\u578b\u5b8c\u6210\u4e00\u6b21\u7b80\u5355\u7684\"\u52a0\"\u4e0e\"\u4e58\"\u51fd\u6570\u8c03\u7528,\u5927\u6a21\u578b\u56de\u590d\u7684\u5de5\u5177\u8c03\u7528\u60c5\u51b5</p> </li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":"<ol> <li>LMDeploy\u73af\u5883</li> <li>LMDeploy\u4e0eInternLM2.5</li> <li>LMDeploy\u4e0eInternVL2</li> <li>LMDeploy\u7684api\u670d\u52a1\u4e0eFunction call</li> </ol>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#31-lmdeploy","title":"3.1 LMDeploy\u73af\u5883","text":"<ul> <li>\u5f00\u53d1\u53ca\u8bbe\u7f6e</li> </ul> <p>30%A100*1(24GB\u663e\u5b58\u5bb9\u91cf)</p> <pre><code>conda create -n lmdeploy  python=3.10 -y\nconda activate lmdeploy\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y\npip install timm==1.0.8 openai==1.40.3 lmdeploy[all]==0.5.3\n</code></pre> <ul> <li>\u83b7\u53d6internlm2_5-7b-chat\u548cInternVL2-26B\u6a21\u578b</li> </ul> <pre><code>mkdir /root/models\nln -s /root/share/new_models//Shanghai_AI_Laboratory/internlm2_5-7b-chat /root/models\nln -s /root/share/new_models/OpenGVLab/InternVL2-26B /root/models\n</code></pre> <p></p> <ul> <li>\u6d4b\u8bd5\u6a21\u578b</li> </ul> <pre><code>conda activate lmdeploy\nlmdeploy chat /root/models/internlm2_5-7b-chat\n</code></pre> <p></p> <p></p> <p></p> <ul> <li>\u670d\u52a1\u90e8\u7f72</li> </ul> <pre><code>conda activate lmdeploy\nlmdeploy serve api_server \\\n    /root/models/internlm2_5-7b-chat \\\n    --model-format hf \\\n    --quant-policy 0 \\\n    --server-name 0.0.0.0 \\\n    --server-port 23333 \\\n    --tp 1\n</code></pre> <ul> <li>\u53e6\u8d77\u4e00\u4e2a\u7ec8\u7aef\u670d\u52a1\u8bbf\u95ee\uff08CLI(\u201c\u547d\u4ee4\u884c\u754c\u9762\u201d Command Line Interface\u7684\u7f29\u5199)-client\uff09</li> </ul> <pre><code>conda activate lmdeploy\nlmdeploy serve api_client http://localhost:23333\n</code></pre> <p></p> <p></p> <ul> <li>\u57fa\u4e8eapi\u670d\u52a1\u8c03\u7528\uff0c\u542f\u52a8gradio\u754c\u9762(\u53e6\u8d77\u7ec8\u7aef)</li> </ul> <pre><code>conda activate lmdeploy\nlmdeploy serve gradio http://localhost:23333 \\\n    --server-name 0.0.0.0 \\\n    --server-port 6006\n</code></pre> <p></p> <p></p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#32-lmdeploy","title":"3.2 LMDeploy\u91cf\u5316","text":"<p>LMDeploy \u63d0\u4f9b\u4e86\u6743\u91cd\u91cf\u5316\u548c k/v cache\u4e24\u79cd\u7b56\u7565\u3002</p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#321-kv-cache","title":"3.2.1 kv cache\u91cf\u5316","text":"<p>kv cache\u662f\u4e00\u79cd\u7f13\u5b58\u6280\u672f\uff0c\u901a\u8fc7\u5b58\u50a8\u952e\u503c\u5bf9\u7684\u5f62\u5f0f\u6765\u590d\u7528\u8ba1\u7b97\u7ed3\u679c\uff0c\u4ee5\u8fbe\u5230\u63d0\u9ad8\u6027\u80fd\u548c\u964d\u4f4e\u5185\u5b58\u6d88\u8017\u7684\u76ee\u7684\u3002</p> <p>\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\uff0ckv cache\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u91cd\u590d\u8ba1\u7b97\u91cf\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0ckv cache\u5168\u90e8\u5b58\u50a8\u4e8e\u663e\u5b58\uff0c\u4ee5\u52a0\u5feb\u8bbf\u5b58\u901f\u5ea6\u3002</p> <p>\u6a21\u578b\u5728\u8fd0\u884c\u65f6\uff0c\u5360\u7528\u7684\u663e\u5b58\u53ef\u5927\u81f4\u5206\u4e3a\u4e09\u90e8\u5206\uff1a\u6a21\u578b\u53c2\u6570\u672c\u8eab\u5360\u7528\u7684\u663e\u5b58\u3001kv cache\u5360\u7528\u7684\u663e\u5b58\uff0c\u4ee5\u53ca\u4e2d\u95f4\u8fd0\u7b97\u7ed3\u679c\u5360\u7528\u7684\u663e\u5b58\u3002</p> <p>\u81ea v0.4.0 \u8d77\uff0cLMDeploy \u652f\u6301\u5728\u7ebf kv cache int4/int8 \u91cf\u5316\uff0c\u91cf\u5316\u65b9\u5f0f\u4e3a per-head per-token \u7684\u975e\u5bf9\u79f0\u91cf\u5316\u3002\u6b64\u5916\uff0c\u901a\u8fc7 LMDeploy \u5e94\u7528 kv \u91cf\u5316\u975e\u5e38\u7b80\u5355\uff0c\u53ea\u9700\u8981\u8bbe\u5b9a quant_policy \u548ccache-max-entry-count\u53c2\u6570\u3002</p> <p>\u76ee\u524d\uff0cLMDeploy \u89c4\u5b9a qant_policy=4 \u8868\u793a kv int4 \u91cf\u5316\uff0cquant_policy=8 \u8868\u793a kv int8 \u91cf\u5316\u3002</p> <pre><code>lmdeploy serve api_server \\\n    /root/models/internlm2_5-7b-chat \\\n    --model-format hf \\\n    --quant-policy 4 \\\n    --cache-max-entry-count 0.4\\\n    --server-name 0.0.0.0 \\\n    --server-port 23333 \\\n    --tp 1\n</code></pre> <p></p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#322","title":"3.2.2 \u6743\u91cd\u91cf\u5316","text":"<p>W4\uff1a\u8fd9\u901a\u5e38\u8868\u793a\u6743\u91cd\u91cf\u5316\u4e3a4\u4f4d\u6574\u6570\uff08int4\uff09\u3002\u8fd9\u610f\u5473\u7740\u6a21\u578b\u4e2d\u7684\u6743\u91cd\u53c2\u6570\u5c06\u4ece\u5b83\u4eec\u539f\u59cb\u7684\u6d6e\u70b9\u8868\u793a\uff08\u4f8b\u5982FP32\u3001BF16\u6216FP16\uff0cInternlm2.5\u7cbe\u5ea6\u4e3aBF16\uff09\u8f6c\u6362\u4e3a4\u4f4d\u7684\u6574\u6570\u8868\u793a\u3002\u8fd9\u6837\u505a\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u6a21\u578b\u7684\u5927\u5c0f\u3002</p> <p>A16\uff1a\u8fd9\u8868\u793a\u6fc0\u6d3b\uff08\u6216\u8f93\u5165/\u8f93\u51fa\uff09\u4ecd\u7136\u4fdd\u6301\u572816\u4f4d\u6d6e\u70b9\u6570\uff08\u4f8b\u5982FP16\u6216BF16\uff09\u3002\u6fc0\u6d3b\u662f\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u4f20\u64ad\u7684\u6570\u636e\uff0c\u901a\u5e38\u5728\u6bcf\u5c42\u8fd0\u7b97\u4e4b\u540e\u4ea7\u751f\u3002</p> <p>\u56e0\u6b64\uff0cW4A16\u7684\u91cf\u5316\u914d\u7f6e\u610f\u5473\u7740\uff1a - \u6743\u91cd\u88ab\u91cf\u5316\u4e3a4\u4f4d\u6574\u6570\u3002 - \u6fc0\u6d3b\u4fdd\u6301\u4e3a16\u4f4d\u6d6e\u70b9\u6570\u3002</p> <p><pre><code>lmdeploy lite auto_awq \\\n   /root/models/internlm2_5-7b-chat \\\n  --calib-dataset 'ptb' \\\n  --calib-samples 128 \\\n  --calib-seqlen 2048 \\\n  --w-bits 4 \\\n  --w-group-size 128 \\\n  --batch-size 1 \\\n  --search-scale False \\\n  --work-dir /root/models/internlm2_5-7b-chat-w4a16-4bit\n  ```\n\n- lmdeploy lite auto_awq: lite\u8fd9\u662fLMDeploy\u7684\u547d\u4ee4\uff0c\u7528\u4e8e\u542f\u52a8\u91cf\u5316\u8fc7\u7a0b\uff0c\u800cauto_awq\u4ee3\u8868\u81ea\u52a8\u6743\u91cd\u91cf\u5316\uff08auto-weight-quantization\uff09\u3002\n- /root/models/internlm2_5-7b-chat: \u6a21\u578b\u6587\u4ef6\u7684\u8def\u5f84\u3002\n- --calib-dataset 'ptb': \u8fd9\u4e2a\u53c2\u6570\u6307\u5b9a\u4e86\u4e00\u4e2a\u6821\u51c6\u6570\u636e\u96c6\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662f\u2019ptb\u2019\uff08Penn Treebank\uff0c\u4e00\u4e2a\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u6570\u636e\u96c6\uff09\u3002\n- --calib-samples 128: \u8fd9\u6307\u5b9a\u4e86\u7528\u4e8e\u6821\u51c6\u7684\u6837\u672c\u6570\u91cf\u2014128\u4e2a\u6837\u672c\n- --calib-seqlen 2048: \u8fd9\u6307\u5b9a\u4e86\u6821\u51c6\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u7684\u5e8f\u5217\u957f\u5ea6\u20142048\n- --w-bits 4: \u8fd9\u8868\u793a\u6743\u91cd\uff08weights\uff09\u7684\u4f4d\u6570\u5c06\u88ab\u91cf\u5316\u4e3a4\u4f4d\u3002\n- --work-dir /root/models/internlm2_5-7b-chat-w4a16-4bit: \u8fd9\u662f\u5de5\u4f5c\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u7528\u4e8e\u5b58\u50a8\u91cf\u5316\u540e\u7684\u6a21\u578b\u548c\u4e2d\u95f4\u7ed3\u679c\u3002\n\n![alt text](image-19.png)\n\n- \u6a21\u578b\u5927\u5c0f\u67e5\u770b\n\n```shell\ndu -sh /root/models/*\n</code></pre> </p> <p>\u5176\u4f59\u6587\u4ef6\u5939\u90fd\u662f\u4ee5\u8f6f\u94fe\u63a5\u7684\u5f62\u5f0f\u5b58\u5728\u7684\uff0c\u4e0d\u5360\u7528\u7a7a\u95f4\uff0c\u6545\u663e\u793a\u4e3a0</p> <p><pre><code>du -sh /root/share/new_models/Shanghai_AI_Laboratory/*\n</code></pre> </p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.3%20LMDeploy%20%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/#33","title":"3.3 \u51fd\u6570\u8c03\u7528\uff08\u5927\u6a21\u578b\u5e94\u7528\uff09","text":"<p>\u5173\u4e8eFunction call\uff0c\u5373\u51fd\u6570\u8c03\u7528\u529f\u80fd\uff0c\u5b83\u5141\u8bb8\u5f00\u53d1\u8005\u5728\u8c03\u7528\u6a21\u578b\u65f6\uff0c\u8be6\u7ec6\u8bf4\u660e\u51fd\u6570\u7684\u4f5c\u7528\uff0c\u5e76\u4f7f\u6a21\u578b\u80fd\u591f\u667a\u80fd\u5730\u6839\u636e\u7528\u6237\u7684\u63d0\u95ee\u6765\u8f93\u5165\u53c2\u6570\u5e76\u6267\u884c\u51fd\u6570\u3002\u5b8c\u6210\u8c03\u7528\u540e\uff0c\u6a21\u578b\u4f1a\u5c06\u51fd\u6570\u7684\u8f93\u51fa\u7ed3\u679c\u4f5c\u4e3a\u56de\u7b54\u7528\u6237\u95ee\u9898\u7684\u4f9d\u636e\u3002</p> <ul> <li>\u90e8\u7f72\u5927\u6a21\u578b\u670d\u52a1</li> </ul> <pre><code>conda activate lmdeploy\nlmdeploy serve api_server \\\n    /root/models/internlm2_5-7b-chat \\\n    --model-format hf \\\n    --quant-policy 0 \\\n    --server-name 0.0.0.0 \\\n    --server-port 23333 \\\n    --tp 1\n</code></pre> <ul> <li>\u521b\u5efa\u51fd\u6570\u6587\u4ef6internlm2_5_func.py</li> </ul> <pre><code>touch /root/internlm2_5_func.py\n</code></pre> <pre><code>from openai import OpenAI\n\n\ndef add(a: int, b: int):\n    return a + b\n\n\ndef mul(a: int, b: int):\n    return a * b\n\n\ntools = [{\n    'type': 'function',\n    'function': {\n        'name': 'add',\n        'description': 'Compute the sum of two numbers',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'a': {\n                    'type': 'int',\n                    'description': 'A number',\n                },\n                'b': {\n                    'type': 'int',\n                    'description': 'A number',\n                },\n            },\n            'required': ['a', 'b'],\n        },\n    }\n}, {\n    'type': 'function',\n    'function': {\n        'name': 'mul',\n        'description': 'Calculate the product of two numbers',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'a': {\n                    'type': 'int',\n                    'description': 'A number',\n                },\n                'b': {\n                    'type': 'int',\n                    'description': 'A number',\n                },\n            },\n            'required': ['a', 'b'],\n        },\n    }\n}]\nmessages = [{'role': 'user', 'content': 'Compute (3+5)*2'}]\n\nclient = OpenAI(api_key='YOUR_API_KEY', base_url='http://0.0.0.0:23333/v1')\nmodel_name = client.models.list().data[0].id\nresponse = client.chat.completions.create(\n    model=model_name,\n    messages=messages,\n    temperature=0.8,\n    top_p=0.8,\n    stream=False,\n    tools=tools)\nprint(response)\nfunc1_name = response.choices[0].message.tool_calls[0].function.name\nfunc1_args = response.choices[0].message.tool_calls[0].function.arguments\nfunc1_out = eval(f'{func1_name}(**{func1_args})')\nprint(func1_out)\n\nmessages.append({\n    'role': 'assistant',\n    'content': response.choices[0].message.content\n})\nmessages.append({\n    'role': 'environment',\n    'content': f'3+5={func1_out}',\n    'name': 'plugin'\n})\nresponse = client.chat.completions.create(\n    model=model_name,\n    messages=messages,\n    temperature=0.8,\n    top_p=0.8,\n    stream=False,\n    tools=tools)\nprint(response)\nfunc2_name = response.choices[0].message.tool_calls[0].function.name\nfunc2_args = response.choices[0].message.tool_calls[0].function.arguments\nfunc2_out = eval(f'{func2_name}(**{func2_args})')\nprint(func2_out)\n</code></pre> <ul> <li>\u8fd0\u884cinternlm2_5_func.py</li> </ul> <p><pre><code>python /root/internlm2_5_func.py\n</code></pre> </p>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/","title":"3.4 InternVL \u591a\u6a21\u6001\u6a21\u578b\u90e8\u7f72\u5fae\u8c03\u5b9e\u8df5","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":"<ul> <li> <p>follow \u6559\u5b66\u6587\u6863\u548c\u89c6\u9891\u4f7f\u7528QLoRA\u8fdb\u884c\u5fae\u8c03\u6a21\u578b\uff0c\u590d\u73b0\u5fae\u8c03\u6548\u679c\uff0c\u5e76\u80fd\u6210\u529f\u8bb2\u51fa\u6897\u56fe.</p> </li> <li> <p>\u5c1d\u8bd5\u4f7f\u7528LoRA\uff0c\u6216\u8c03\u6574xtuner\u7684config\uff0c\u5982LoRA rank\uff0c\u5b66\u4e60\u7387\u3002\u770b\u6a21\u578bLoss\u4f1a\u5982\u4f55\u53d8\u5316\uff0c\u5e76\u8bb0\u5f55\u8c03\u6574\u540e\u6548\u679c(\u9009\u505a\uff0c\u4f7f\u7528LoRA\u6216\u8c03\u6574config\u53ef\u4ee5\u4e8c\u9009\u4e00)</p> </li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":"<ul> <li> <p>\u590d\u73b0\u56fe\u6897</p> </li> <li> <p>LoRA\u5fae\u8c03</p> </li> </ul>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.4%20InternVL%20%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BE%AE%E8%B0%83%E5%AE%9E%E8%B7%B5/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":"<ul> <li>Step1\uff1a\u5f00\u53d1\u673a\u521b\u5efa</li> </ul> <ul> <li>Step2: InternVL2-2B \u6a21\u578b\u83b7\u53d6</li> </ul> <p><pre><code>cd /root\nmkdir -p models\n\ncp \u6a21\u578b\n\ncp -r /root/share/new_models/OpenGVLab/InternVL2-2B /root/models/\n</code></pre> </p> <ul> <li>Step3: \u4f9d\u8d56\u5e93\u5b89\u88c5</li> </ul> <pre><code>conda create --name xtuner python=3.10 -y\n\n# \u6fc0\u6d3b\u865a\u62df\u73af\u5883\uff08\u6ce8\u610f\uff1a\u540e\u7eed\u7684\u6240\u6709\u64cd\u4f5c\u90fd\u9700\u8981\u5728\u8fd9\u4e2a\u865a\u62df\u73af\u5883\u4e2d\u8fdb\u884c\uff09\nconda activate xtuner\n\n# \u5b89\u88c5\u4e00\u4e9b\u5fc5\u8981\u7684\u5e93\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y\n# \u5b89\u88c5\u5176\u4ed6\u4f9d\u8d56\napt install libaio-dev\npip install transformers==4.39.3\npip install streamlit==1.36.0\npip install lmdeploy==0.5.3\n</code></pre> <ul> <li>Step4: \u83b7\u53d6\u6570\u636e</li> </ul> <pre><code>## \u9996\u5148\u8ba9\u6211\u4eec\u5b89\u88c5\u4e00\u4e0b\u9700\u8981\u7684\u5305\npip install datasets matplotlib Pillow timm\n\n## \u8ba9\u6211\u4eec\u628a\u6570\u636e\u96c6\u632a\u51fa\u6765\ncp -r /root/share/new_models/datasets/CLoT_cn_2000 /root/pro/datas/\n</code></pre> <ul> <li>Step5: InternVL2-2B \u5355\u56fe\u63a8\u7406</li> </ul> <pre><code>## \u83b7\u53d6\u5355\u56fe\n\ncp /root/pro/datas/CLoT_cn_2000/ex_images/007aPnLRgy1hb39z0im50j30ci0el0wm.jpg /root/pro/\n</code></pre> <p></p> <pre><code>##\u521b\u5efa\u4ee3\u7801\u6d4b\u8bd5\ntouch /root/pro/test_lmdeploy.py\ncd /root/pro/\n</code></pre> <pre><code>from lmdeploy import pipeline\nfrom lmdeploy.vl import load_image\n\npipe = pipeline('/root/model/InternVL2-2B')\n\nimage = load_image('/root/InternLM/007aPnLRgy1hb39z0im50j30ci0el0wm.jpg')\nresponse = pipe(('\u8bf7\u4f60\u6839\u636e\u8fd9\u5f20\u56fe\u7247\uff0c\u8bb2\u4e00\u4e2a\u8111\u6d1e\u5927\u5f00\u7684\u6897', image))\nprint(response.text)\n</code></pre> <ul> <li>Step6: \u6a21\u578b\u5fae\u8c03\u8bbe\u7f6e</li> </ul> <pre><code>##\u914d\u7f6e\u5fae\u8c03\u53c2\u6570\n\n## \u4fee\u6539\uff1aXTuner/xtuner/configs/internvl/v2/internvl_v2_internlm2_2b_qlora_finetune.py\u4e2d\u7684Model\u548cdata\n</code></pre> <pre><code>#######################################################################\n#                          PART 1  Settings                           #\n#######################################################################\n# Model\npath = '/root/models/InternVL2-2B'\n\n# Data\ndata_root = '/root/pro/datas/CLoT_cn_2000/'\ndata_path = data_root + 'ex_cn.json'\nimage_folder = data_root\nprompt_template = PROMPT_TEMPLATE.internlm2_chat\nmax_length = 6656\n</code></pre> <p></p> <ul> <li>Step7: \u5f00\u59cb\u8bad\u7ec3</li> </ul> <pre><code>NPROC_PER_NODE=1 xtuner train /root/pro/XTuner/xtuner/configs/internvl/v2/internvl_v2_internlm2_2b_qlora_finetune.py  --work-dir /root/pro/work_dirs/internvl_ft_run_8_filter  --deepspeed deepspeed_zero1\n</code></pre> <ul> <li>Step8: \u5408\u5e76\u6743\u91cd&amp;&amp;\u6a21\u578b\u8f6c\u6362</li> </ul> <pre><code>python3 /root/XTuner/xtuner/configs/internvl/v1_5/convert_to_official.py /root/XTuner/xtuner/configs/internvl/v2/internvl_v2_internlm2_5_8b_qlora_finetune.py /root/work_dirs/internvl_ft_run_8_filter/iter_3000.pth /root/models/InternVL2-2B-qlora/\n</code></pre>"},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/","title":"3.5 \u8334\u9999\u8c46\uff1a\u4f01\u4e1a\u7ea7\u77e5\u8bc6\u5e93\u95ee\u7b54\u5de5\u5177","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#_1","title":"\u4e00\u3001\u4efb\u52a1\u8bf4\u660e","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#1","title":"1.\u57fa\u7840\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#2","title":"2.\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#_2","title":"\u4e8c\u3001\u4efb\u52a1\u63d0\u4ea4","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#_3","title":"\u57fa\u7840\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#_4","title":"\u8fdb\u9636\u4efb\u52a1","text":""},{"location":"%E8%BF%9B%E9%98%B6%E5%B2%9B/3.5%20%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7/#_5","title":"\u4e09\u3001\u590d\u73b0\u6b65\u9aa4","text":""}]}